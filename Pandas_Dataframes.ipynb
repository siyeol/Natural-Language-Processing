{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Week3_Pandas_Dataframes_Homework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siyeol/Natural-Language-Processing/blob/main/Pandas_Dataframes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxaoPF2FoB7j"
      },
      "source": [
        "# Software Coaching for Python\n",
        "# Week 3: Pandas Dataframes - Homework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRIkFlyeoB7p"
      },
      "source": [
        "Instructor: Kang-Pyo Lee "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GLAHQoApBMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b9620f-d858-4fcb-bfa1-bf1e838f5adb"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path = \"/content/gdrive/Shareddrives/SW_Coaching_for_Python\"\n",
        "my_folder = \"SYC\"     # *** REPLACE WITH YOUR FOLDER NAME ***\n",
        "outcome_folder = f\"{path}/{my_folder}/outcome\"\n",
        "classdata_folder = f\"{path}/classdata\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd_6Xe7Xzpij"
      },
      "source": [
        "## Element Selection from a Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Oi6IXWzpik",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "860fa47f-e911-4988-e274-8876b43cbc0c"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 150)\n",
        "\n",
        "df = pd.read_csv(f\"{classdata_folder}/timeline_NASA.csv\", sep=\"\\t\")\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>retweet_created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1354552906175934477</td>\n",
              "      <td>Wed Jan 27 22:12:33 +0000 2021</td>\n",
              "      <td>It once held a lake. And what we're going to do, as soon as we get there, is to explore the rocks that were deposi‚Ä¶ https://t.co/UW9wngvx4C</td>\n",
              "      <td>72</td>\n",
              "      <td>462</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1354549784061865986</td>\n",
              "      <td>Wed Jan 27 22:00:09 +0000 2021</td>\n",
              "      <td>I asked the team [...] to come up with something that would symbolize, to mark this challenge and thank in particu‚Ä¶ https://t.co/QH235r9zjq</td>\n",
              "      <td>50</td>\n",
              "      <td>361</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1354546326139265030</td>\n",
              "      <td>Wed Jan 27 21:46:25 +0000 2021</td>\n",
              "      <td>Perseverance is the very first rover designed to seek signs of past microbial life, by collecting and caching rock‚Ä¶ https://t.co/nn72OHRVv6</td>\n",
              "      <td>135</td>\n",
              "      <td>870</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1354542309988327425</td>\n",
              "      <td>Wed Jan 27 21:30:27 +0000 2021</td>\n",
              "      <td>üî¥ LIVE: Tune in for a preview of the next Mars landing! On Feb. 18, our @NASAPersevere rover will arrive at the Red‚Ä¶ https://t.co/rHRhIrzXWR</td>\n",
              "      <td>374</td>\n",
              "      <td>1430</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1354540246436872195</td>\n",
              "      <td>Wed Jan 27 21:22:15 +0000 2021</td>\n",
              "      <td>RT @NASAMars: Don't forget to join us for today's briefing at 4:30pm ET (21:30 UTC): https://t.co/fGItMYWnFR Tag your questions #Countdown‚Ä¶</td>\n",
              "      <td>137</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Wed Jan 27 20:18:56 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3195</th>\n",
              "      <td>1265370733930307585</td>\n",
              "      <td>Tue May 26 19:54:27 +0000 2020</td>\n",
              "      <td>RT @NASAKennedy: Looking for live views of the launch pad? We got you covered. üöÄüëÄCheck out the rocket that will carry @AstroBehnken and @‚Ä¶</td>\n",
              "      <td>1197</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Tue May 26 19:36:00 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3196</th>\n",
              "      <td>1265365848098816002</td>\n",
              "      <td>Tue May 26 19:35:02 +0000 2020</td>\n",
              "      <td>For the first time since 2011, we‚Äôre sending American astronauts back to space, on an American rocket, from America‚Ä¶ https://t.co/FsC1feO84c</td>\n",
              "      <td>622</td>\n",
              "      <td>2614</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3197</th>\n",
              "      <td>1265327291468562432</td>\n",
              "      <td>Tue May 26 17:01:49 +0000 2020</td>\n",
              "      <td>LIVE: Want to go behind-the-scenes of #LaunchAmerica?Join our experts on @reddit to ask questions about the missi‚Ä¶ https://t.co/p7iqJY4jyX</td>\n",
              "      <td>253</td>\n",
              "      <td>1942</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3198</th>\n",
              "      <td>1265327258274840576</td>\n",
              "      <td>Tue May 26 17:01:41 +0000 2020</td>\n",
              "      <td>@brandonleblanc @SpaceX @AmyShiraTeitel See you online! https://t.co/FaQ7K75sBP</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3199</th>\n",
              "      <td>1265317908068085761</td>\n",
              "      <td>Tue May 26 16:24:32 +0000 2020</td>\n",
              "      <td>RT @NASAEarth: Ready to #LaunchAmerica? Tomorrow, two astronauts üë®üèª‚ÄçüöÄüë®üèª‚ÄçüöÄ are launching üöÄ to the @Space_Station from @NASAKennedy‚Äôs histori‚Ä¶</td>\n",
              "      <td>595</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Tue May 26 16:09:54 +0000 2020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3200 rows √ó 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                status_id  ...              retweet_created_at\n",
              "0     1354552906175934477  ...                             NaN\n",
              "1     1354549784061865986  ...                             NaN\n",
              "2     1354546326139265030  ...                             NaN\n",
              "3     1354542309988327425  ...                             NaN\n",
              "4     1354540246436872195  ...  Wed Jan 27 20:18:56 +0000 2021\n",
              "...                   ...  ...                             ...\n",
              "3195  1265370733930307585  ...  Tue May 26 19:36:00 +0000 2020\n",
              "3196  1265365848098816002  ...                             NaN\n",
              "3197  1265327291468562432  ...                             NaN\n",
              "3198  1265327258274840576  ...                             NaN\n",
              "3199  1265317908068085761  ...  Tue May 26 16:09:54 +0000 2020\n",
              "\n",
              "[3200 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkCY_jeNzpil"
      },
      "source": [
        "1\\. Get the list of column labels of `df`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eAVTJWalzpil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3621e8fc-a98d-48c7-e220-1aa05dcd7e99"
      },
      "source": [
        "# Your answer here\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['status_id', 'created_at', 'text', 'retweet_count', 'favorite_count',\n",
              "       'is_retweet', 'retweet_created_at'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh4RZaRzpim"
      },
      "source": [
        "2\\. Get the list of row index positions of `df`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NsJ_IkkPzpim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0ddaff-f18a-4240-ad00-3b5d248bc0da"
      },
      "source": [
        "# Your answer here\n",
        "df.index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RangeIndex(start=0, stop=3200, step=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twe2nzNozpim"
      },
      "source": [
        "3\\. Get the shape of `df`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_aOKNrGIzpin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae4d5f9-b57d-4b44-c6f1-6f2071782715"
      },
      "source": [
        "# Your answer here\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3200, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPb52VBizpin"
      },
      "source": [
        "4\\. Get the number of rows in `df`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1wyW4oEmzpin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0625e8d0-8f90-41ae-a9db-15a95b7bdde9"
      },
      "source": [
        "# Your answer here\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3200 entries, 0 to 3199\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   status_id           3200 non-null   int64 \n",
            " 1   created_at          3200 non-null   object\n",
            " 2   text                3200 non-null   object\n",
            " 3   retweet_count       3200 non-null   int64 \n",
            " 4   favorite_count      3200 non-null   int64 \n",
            " 5   is_retweet          3200 non-null   int64 \n",
            " 6   retweet_created_at  816 non-null    object\n",
            "dtypes: int64(4), object(3)\n",
            "memory usage: 175.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlMXs4ouzpin"
      },
      "source": [
        "5\\. Select all values from the `created_at` column. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nskx1-Ldzpin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5a814f-2c2f-431a-90b6-a91b947dabb0"
      },
      "source": [
        "# Your answer here\n",
        "list(df.created_at)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wed Jan 27 22:12:33 +0000 2021',\n",
              " 'Wed Jan 27 22:00:09 +0000 2021',\n",
              " 'Wed Jan 27 21:46:25 +0000 2021',\n",
              " 'Wed Jan 27 21:30:27 +0000 2021',\n",
              " 'Wed Jan 27 21:22:15 +0000 2021',\n",
              " 'Wed Jan 27 20:04:59 +0000 2021',\n",
              " 'Wed Jan 27 19:32:23 +0000 2021',\n",
              " 'Wed Jan 27 19:15:05 +0000 2021',\n",
              " 'Wed Jan 27 18:36:21 +0000 2021',\n",
              " 'Wed Jan 27 18:01:20 +0000 2021',\n",
              " 'Wed Jan 27 17:45:42 +0000 2021',\n",
              " 'Wed Jan 27 17:30:07 +0000 2021',\n",
              " 'Wed Jan 27 16:46:56 +0000 2021',\n",
              " 'Wed Jan 27 16:30:23 +0000 2021',\n",
              " 'Wed Jan 27 16:13:55 +0000 2021',\n",
              " 'Wed Jan 27 15:23:35 +0000 2021',\n",
              " 'Wed Jan 27 15:12:23 +0000 2021',\n",
              " 'Wed Jan 27 14:59:16 +0000 2021',\n",
              " 'Wed Jan 27 14:58:34 +0000 2021',\n",
              " 'Wed Jan 27 14:28:32 +0000 2021',\n",
              " 'Wed Jan 27 14:07:34 +0000 2021',\n",
              " 'Wed Jan 27 13:38:24 +0000 2021',\n",
              " 'Wed Jan 27 13:31:15 +0000 2021',\n",
              " 'Wed Jan 27 13:23:47 +0000 2021',\n",
              " 'Wed Jan 27 13:10:20 +0000 2021',\n",
              " 'Wed Jan 27 13:07:20 +0000 2021',\n",
              " 'Wed Jan 27 13:06:15 +0000 2021',\n",
              " 'Wed Jan 27 13:01:11 +0000 2021',\n",
              " 'Wed Jan 27 12:17:09 +0000 2021',\n",
              " 'Wed Jan 27 12:04:28 +0000 2021',\n",
              " 'Wed Jan 27 11:32:50 +0000 2021',\n",
              " 'Wed Jan 27 11:01:33 +0000 2021',\n",
              " 'Wed Jan 27 10:30:50 +0000 2021',\n",
              " 'Wed Jan 27 10:15:49 +0000 2021',\n",
              " 'Wed Jan 27 01:55:19 +0000 2021',\n",
              " 'Tue Jan 26 23:25:01 +0000 2021',\n",
              " 'Tue Jan 26 22:10:32 +0000 2021',\n",
              " 'Tue Jan 26 21:48:29 +0000 2021',\n",
              " 'Tue Jan 26 20:04:46 +0000 2021',\n",
              " 'Tue Jan 26 19:28:00 +0000 2021',\n",
              " 'Tue Jan 26 17:46:10 +0000 2021',\n",
              " 'Tue Jan 26 17:30:39 +0000 2021',\n",
              " 'Tue Jan 26 17:19:09 +0000 2021',\n",
              " 'Tue Jan 26 16:24:12 +0000 2021',\n",
              " 'Tue Jan 26 15:57:21 +0000 2021',\n",
              " 'Tue Jan 26 15:33:52 +0000 2021',\n",
              " 'Mon Jan 25 23:26:17 +0000 2021',\n",
              " 'Mon Jan 25 23:14:47 +0000 2021',\n",
              " 'Mon Jan 25 21:05:06 +0000 2021',\n",
              " 'Mon Jan 25 15:33:01 +0000 2021',\n",
              " 'Mon Jan 25 15:24:00 +0000 2021',\n",
              " 'Sun Jan 24 22:25:07 +0000 2021',\n",
              " 'Sun Jan 24 19:55:01 +0000 2021',\n",
              " 'Sun Jan 24 19:52:29 +0000 2021',\n",
              " 'Sat Jan 23 21:59:16 +0000 2021',\n",
              " 'Sat Jan 23 21:26:11 +0000 2021',\n",
              " 'Sat Jan 23 20:45:01 +0000 2021',\n",
              " 'Sat Jan 23 17:32:00 +0000 2021',\n",
              " 'Sat Jan 23 01:57:25 +0000 2021',\n",
              " 'Fri Jan 22 23:08:00 +0000 2021',\n",
              " 'Fri Jan 22 20:00:42 +0000 2021',\n",
              " 'Fri Jan 22 19:19:29 +0000 2021',\n",
              " 'Fri Jan 22 18:24:04 +0000 2021',\n",
              " 'Fri Jan 22 17:57:08 +0000 2021',\n",
              " 'Fri Jan 22 16:32:00 +0000 2021',\n",
              " 'Fri Jan 22 02:07:02 +0000 2021',\n",
              " 'Thu Jan 21 23:33:45 +0000 2021',\n",
              " 'Thu Jan 21 22:32:05 +0000 2021',\n",
              " 'Thu Jan 21 21:37:30 +0000 2021',\n",
              " 'Thu Jan 21 20:14:52 +0000 2021',\n",
              " 'Wed Jan 20 16:02:46 +0000 2021',\n",
              " 'Wed Jan 20 01:10:01 +0000 2021',\n",
              " 'Tue Jan 19 22:35:16 +0000 2021',\n",
              " 'Tue Jan 19 22:19:50 +0000 2021',\n",
              " 'Tue Jan 19 22:16:09 +0000 2021',\n",
              " 'Tue Jan 19 21:58:35 +0000 2021',\n",
              " 'Tue Jan 19 20:56:00 +0000 2021',\n",
              " 'Tue Jan 19 17:15:00 +0000 2021',\n",
              " 'Tue Jan 19 16:32:22 +0000 2021',\n",
              " 'Tue Jan 19 01:27:06 +0000 2021',\n",
              " 'Mon Jan 18 21:34:39 +0000 2021',\n",
              " 'Mon Jan 18 20:36:20 +0000 2021',\n",
              " 'Mon Jan 18 16:04:00 +0000 2021',\n",
              " 'Mon Jan 18 15:51:53 +0000 2021',\n",
              " 'Mon Jan 18 15:09:26 +0000 2021',\n",
              " 'Mon Jan 18 02:37:26 +0000 2021',\n",
              " 'Sun Jan 17 20:08:06 +0000 2021',\n",
              " 'Sun Jan 17 19:42:47 +0000 2021',\n",
              " 'Sun Jan 17 17:44:53 +0000 2021',\n",
              " 'Sun Jan 17 17:18:43 +0000 2021',\n",
              " 'Sun Jan 17 02:50:22 +0000 2021',\n",
              " 'Sun Jan 17 02:16:22 +0000 2021',\n",
              " 'Sun Jan 17 02:01:05 +0000 2021',\n",
              " 'Sun Jan 17 02:00:05 +0000 2021',\n",
              " 'Sun Jan 17 01:30:57 +0000 2021',\n",
              " 'Sun Jan 17 01:14:14 +0000 2021',\n",
              " 'Sun Jan 17 01:06:54 +0000 2021',\n",
              " 'Sun Jan 17 00:16:47 +0000 2021',\n",
              " 'Sat Jan 16 23:47:50 +0000 2021',\n",
              " 'Sat Jan 16 22:39:59 +0000 2021',\n",
              " 'Sat Jan 16 22:19:50 +0000 2021',\n",
              " 'Sat Jan 16 22:17:03 +0000 2021',\n",
              " 'Sat Jan 16 22:14:39 +0000 2021',\n",
              " 'Sat Jan 16 21:35:53 +0000 2021',\n",
              " 'Sat Jan 16 21:09:36 +0000 2021',\n",
              " 'Sat Jan 16 20:59:57 +0000 2021',\n",
              " 'Sat Jan 16 20:43:06 +0000 2021',\n",
              " 'Sat Jan 16 20:40:33 +0000 2021',\n",
              " 'Sat Jan 16 20:36:34 +0000 2021',\n",
              " 'Sat Jan 16 20:35:12 +0000 2021',\n",
              " 'Sat Jan 16 20:31:14 +0000 2021',\n",
              " 'Sat Jan 16 20:30:34 +0000 2021',\n",
              " 'Sat Jan 16 20:20:37 +0000 2021',\n",
              " 'Sat Jan 16 19:39:04 +0000 2021',\n",
              " 'Sat Jan 16 18:00:03 +0000 2021',\n",
              " 'Sat Jan 16 17:44:28 +0000 2021',\n",
              " 'Sat Jan 16 17:24:46 +0000 2021',\n",
              " 'Sat Jan 16 17:03:56 +0000 2021',\n",
              " 'Sat Jan 16 02:01:24 +0000 2021',\n",
              " 'Sat Jan 16 00:46:13 +0000 2021',\n",
              " 'Fri Jan 15 23:26:06 +0000 2021',\n",
              " 'Fri Jan 15 23:22:42 +0000 2021',\n",
              " 'Fri Jan 15 22:25:01 +0000 2021',\n",
              " 'Fri Jan 15 21:51:34 +0000 2021',\n",
              " 'Fri Jan 15 21:16:05 +0000 2021',\n",
              " 'Fri Jan 15 20:25:27 +0000 2021',\n",
              " 'Fri Jan 15 20:11:42 +0000 2021',\n",
              " 'Fri Jan 15 18:50:47 +0000 2021',\n",
              " 'Fri Jan 15 17:03:16 +0000 2021',\n",
              " 'Fri Jan 15 16:27:35 +0000 2021',\n",
              " 'Fri Jan 15 16:16:38 +0000 2021',\n",
              " 'Fri Jan 15 16:12:14 +0000 2021',\n",
              " 'Fri Jan 15 16:10:00 +0000 2021',\n",
              " 'Fri Jan 15 14:53:16 +0000 2021',\n",
              " 'Fri Jan 15 14:35:41 +0000 2021',\n",
              " 'Thu Jan 14 23:20:00 +0000 2021',\n",
              " 'Thu Jan 14 22:58:00 +0000 2021',\n",
              " 'Thu Jan 14 22:21:01 +0000 2021',\n",
              " 'Thu Jan 14 21:48:14 +0000 2021',\n",
              " 'Thu Jan 14 20:11:37 +0000 2021',\n",
              " 'Thu Jan 14 19:49:35 +0000 2021',\n",
              " 'Thu Jan 14 18:03:22 +0000 2021',\n",
              " 'Thu Jan 14 17:24:37 +0000 2021',\n",
              " 'Thu Jan 14 13:02:30 +0000 2021',\n",
              " 'Thu Jan 14 06:27:39 +0000 2021',\n",
              " 'Thu Jan 14 01:49:39 +0000 2021',\n",
              " 'Thu Jan 14 01:35:29 +0000 2021',\n",
              " 'Thu Jan 14 01:33:54 +0000 2021',\n",
              " 'Wed Jan 13 20:36:56 +0000 2021',\n",
              " 'Wed Jan 13 20:12:09 +0000 2021',\n",
              " 'Wed Jan 13 18:49:59 +0000 2021',\n",
              " 'Wed Jan 13 17:35:01 +0000 2021',\n",
              " 'Wed Jan 13 16:14:39 +0000 2021',\n",
              " 'Wed Jan 13 16:13:07 +0000 2021',\n",
              " 'Wed Jan 13 16:11:04 +0000 2021',\n",
              " 'Wed Jan 13 16:03:51 +0000 2021',\n",
              " 'Wed Jan 13 01:16:31 +0000 2021',\n",
              " 'Tue Jan 12 22:35:01 +0000 2021',\n",
              " 'Tue Jan 12 21:04:00 +0000 2021',\n",
              " 'Tue Jan 12 20:55:41 +0000 2021',\n",
              " 'Tue Jan 12 19:28:30 +0000 2021',\n",
              " 'Tue Jan 12 18:04:30 +0000 2021',\n",
              " 'Tue Jan 12 17:27:01 +0000 2021',\n",
              " 'Tue Jan 12 17:22:13 +0000 2021',\n",
              " 'Tue Jan 12 16:55:50 +0000 2021',\n",
              " 'Tue Jan 12 14:44:00 +0000 2021',\n",
              " 'Tue Jan 12 14:09:09 +0000 2021',\n",
              " 'Tue Jan 12 13:53:37 +0000 2021',\n",
              " 'Tue Jan 12 13:47:26 +0000 2021',\n",
              " 'Tue Jan 12 13:40:01 +0000 2021',\n",
              " 'Tue Jan 12 13:31:50 +0000 2021',\n",
              " 'Tue Jan 12 13:00:37 +0000 2021',\n",
              " 'Tue Jan 12 12:38:26 +0000 2021',\n",
              " 'Tue Jan 12 04:56:58 +0000 2021',\n",
              " 'Mon Jan 11 23:43:48 +0000 2021',\n",
              " 'Mon Jan 11 22:45:01 +0000 2021',\n",
              " 'Mon Jan 11 19:29:53 +0000 2021',\n",
              " 'Mon Jan 11 17:34:29 +0000 2021',\n",
              " 'Mon Jan 11 17:29:05 +0000 2021',\n",
              " 'Mon Jan 11 16:40:01 +0000 2021',\n",
              " 'Mon Jan 11 15:54:17 +0000 2021',\n",
              " 'Mon Jan 11 15:45:25 +0000 2021',\n",
              " 'Mon Jan 11 15:24:38 +0000 2021',\n",
              " 'Mon Jan 11 15:04:33 +0000 2021',\n",
              " 'Mon Jan 11 14:54:06 +0000 2021',\n",
              " 'Mon Jan 11 14:11:03 +0000 2021',\n",
              " 'Mon Jan 11 14:00:46 +0000 2021',\n",
              " 'Mon Jan 11 13:51:44 +0000 2021',\n",
              " 'Mon Jan 11 01:03:01 +0000 2021',\n",
              " 'Sun Jan 10 21:13:00 +0000 2021',\n",
              " 'Sun Jan 10 00:36:30 +0000 2021',\n",
              " 'Sat Jan 09 23:21:00 +0000 2021',\n",
              " 'Sat Jan 09 20:14:06 +0000 2021',\n",
              " 'Sat Jan 09 19:54:46 +0000 2021',\n",
              " 'Sat Jan 09 17:03:58 +0000 2021',\n",
              " 'Sat Jan 09 02:05:22 +0000 2021',\n",
              " 'Fri Jan 08 22:46:01 +0000 2021',\n",
              " 'Fri Jan 08 22:03:31 +0000 2021',\n",
              " 'Fri Jan 08 20:56:25 +0000 2021',\n",
              " 'Fri Jan 08 20:16:25 +0000 2021',\n",
              " 'Fri Jan 08 19:44:40 +0000 2021',\n",
              " 'Fri Jan 08 19:23:00 +0000 2021',\n",
              " 'Fri Jan 08 16:17:11 +0000 2021',\n",
              " 'Fri Jan 08 14:22:12 +0000 2021',\n",
              " 'Fri Jan 08 00:10:06 +0000 2021',\n",
              " 'Thu Jan 07 22:40:01 +0000 2021',\n",
              " 'Thu Jan 07 21:41:49 +0000 2021',\n",
              " 'Thu Jan 07 17:58:01 +0000 2021',\n",
              " 'Thu Jan 07 17:06:42 +0000 2021',\n",
              " 'Thu Jan 07 16:23:51 +0000 2021',\n",
              " 'Thu Jan 07 16:04:42 +0000 2021',\n",
              " 'Thu Jan 07 15:57:05 +0000 2021',\n",
              " 'Thu Jan 07 15:46:07 +0000 2021',\n",
              " 'Wed Jan 06 18:54:48 +0000 2021',\n",
              " 'Wed Jan 06 17:18:01 +0000 2021',\n",
              " 'Wed Jan 06 16:59:26 +0000 2021',\n",
              " 'Wed Jan 06 16:26:02 +0000 2021',\n",
              " 'Wed Jan 06 15:35:25 +0000 2021',\n",
              " 'Wed Jan 06 15:31:19 +0000 2021',\n",
              " 'Wed Jan 06 15:17:25 +0000 2021',\n",
              " 'Wed Jan 06 15:03:23 +0000 2021',\n",
              " 'Wed Jan 06 14:50:47 +0000 2021',\n",
              " 'Wed Jan 06 14:45:34 +0000 2021',\n",
              " 'Wed Jan 06 14:10:27 +0000 2021',\n",
              " 'Wed Jan 06 00:47:34 +0000 2021',\n",
              " 'Wed Jan 06 00:35:01 +0000 2021',\n",
              " 'Tue Jan 05 23:02:01 +0000 2021',\n",
              " 'Tue Jan 05 21:49:21 +0000 2021',\n",
              " 'Tue Jan 05 19:32:01 +0000 2021',\n",
              " 'Tue Jan 05 17:58:45 +0000 2021',\n",
              " 'Tue Jan 05 17:05:00 +0000 2021',\n",
              " 'Tue Jan 05 00:04:06 +0000 2021',\n",
              " 'Mon Jan 04 21:56:00 +0000 2021',\n",
              " 'Mon Jan 04 21:25:15 +0000 2021',\n",
              " 'Mon Jan 04 20:58:46 +0000 2021',\n",
              " 'Mon Jan 04 19:30:01 +0000 2021',\n",
              " 'Mon Jan 04 17:40:10 +0000 2021',\n",
              " 'Mon Jan 04 16:06:17 +0000 2021',\n",
              " 'Sun Jan 03 23:19:06 +0000 2021',\n",
              " 'Sun Jan 03 20:10:22 +0000 2021',\n",
              " 'Sun Jan 03 16:57:00 +0000 2021',\n",
              " 'Sat Jan 02 21:15:00 +0000 2021',\n",
              " 'Sat Jan 02 17:55:00 +0000 2021',\n",
              " 'Fri Jan 01 23:30:00 +0000 2021',\n",
              " 'Fri Jan 01 20:55:01 +0000 2021',\n",
              " 'Fri Jan 01 19:00:51 +0000 2021',\n",
              " 'Fri Jan 01 18:11:57 +0000 2021',\n",
              " 'Fri Jan 01 16:10:28 +0000 2021',\n",
              " 'Fri Jan 01 02:04:49 +0000 2021',\n",
              " 'Thu Dec 31 23:10:30 +0000 2020',\n",
              " 'Thu Dec 31 20:13:01 +0000 2020',\n",
              " 'Thu Dec 31 19:46:19 +0000 2020',\n",
              " 'Thu Dec 31 19:12:51 +0000 2020',\n",
              " 'Thu Dec 31 18:18:00 +0000 2020',\n",
              " 'Thu Dec 31 17:04:53 +0000 2020',\n",
              " 'Thu Dec 31 16:35:03 +0000 2020',\n",
              " 'Thu Dec 31 14:48:50 +0000 2020',\n",
              " 'Wed Dec 30 22:55:00 +0000 2020',\n",
              " 'Wed Dec 30 20:49:04 +0000 2020',\n",
              " 'Wed Dec 30 20:43:35 +0000 2020',\n",
              " 'Wed Dec 30 17:36:20 +0000 2020',\n",
              " 'Wed Dec 30 16:21:17 +0000 2020',\n",
              " 'Wed Dec 30 00:08:01 +0000 2020',\n",
              " 'Tue Dec 29 22:42:01 +0000 2020',\n",
              " 'Tue Dec 29 20:42:29 +0000 2020',\n",
              " 'Tue Dec 29 20:00:40 +0000 2020',\n",
              " 'Tue Dec 29 19:05:00 +0000 2020',\n",
              " 'Tue Dec 29 16:40:29 +0000 2020',\n",
              " 'Tue Dec 29 16:06:28 +0000 2020',\n",
              " 'Tue Dec 29 00:40:07 +0000 2020',\n",
              " 'Mon Dec 28 23:04:49 +0000 2020',\n",
              " 'Mon Dec 28 22:30:26 +0000 2020',\n",
              " 'Mon Dec 28 21:36:02 +0000 2020',\n",
              " 'Mon Dec 28 20:20:01 +0000 2020',\n",
              " 'Mon Dec 28 17:56:01 +0000 2020',\n",
              " 'Mon Dec 28 14:09:02 +0000 2020',\n",
              " 'Sun Dec 27 20:15:01 +0000 2020',\n",
              " 'Sun Dec 27 17:05:07 +0000 2020',\n",
              " 'Sun Dec 27 00:10:43 +0000 2020',\n",
              " 'Sat Dec 26 21:08:06 +0000 2020',\n",
              " 'Sat Dec 26 19:10:01 +0000 2020',\n",
              " 'Sat Dec 26 17:05:00 +0000 2020',\n",
              " 'Fri Dec 25 22:54:06 +0000 2020',\n",
              " 'Fri Dec 25 19:20:01 +0000 2020',\n",
              " 'Fri Dec 25 17:18:01 +0000 2020',\n",
              " 'Fri Dec 25 15:10:06 +0000 2020',\n",
              " 'Thu Dec 24 23:15:06 +0000 2020',\n",
              " 'Thu Dec 24 21:12:18 +0000 2020',\n",
              " 'Thu Dec 24 18:56:57 +0000 2020',\n",
              " 'Thu Dec 24 16:10:00 +0000 2020',\n",
              " 'Thu Dec 24 11:57:15 +0000 2020',\n",
              " 'Thu Dec 24 06:27:52 +0000 2020',\n",
              " 'Thu Dec 24 00:56:00 +0000 2020',\n",
              " 'Wed Dec 23 23:08:01 +0000 2020',\n",
              " 'Wed Dec 23 20:10:02 +0000 2020',\n",
              " 'Wed Dec 23 19:48:18 +0000 2020',\n",
              " 'Wed Dec 23 18:24:00 +0000 2020',\n",
              " 'Wed Dec 23 17:05:00 +0000 2020',\n",
              " 'Wed Dec 23 14:08:53 +0000 2020',\n",
              " 'Wed Dec 23 01:05:00 +0000 2020',\n",
              " 'Tue Dec 22 22:55:49 +0000 2020',\n",
              " 'Tue Dec 22 22:43:03 +0000 2020',\n",
              " 'Tue Dec 22 21:45:03 +0000 2020',\n",
              " 'Tue Dec 22 21:24:40 +0000 2020',\n",
              " 'Tue Dec 22 18:06:00 +0000 2020',\n",
              " 'Tue Dec 22 17:22:45 +0000 2020',\n",
              " 'Tue Dec 22 16:43:27 +0000 2020',\n",
              " 'Tue Dec 22 16:42:54 +0000 2020',\n",
              " 'Tue Dec 22 16:42:20 +0000 2020',\n",
              " 'Tue Dec 22 16:41:39 +0000 2020',\n",
              " 'Tue Dec 22 16:41:06 +0000 2020',\n",
              " 'Tue Dec 22 16:39:44 +0000 2020',\n",
              " 'Tue Dec 22 16:38:37 +0000 2020',\n",
              " 'Tue Dec 22 16:20:00 +0000 2020',\n",
              " 'Tue Dec 22 11:30:16 +0000 2020',\n",
              " 'Tue Dec 22 00:35:00 +0000 2020',\n",
              " 'Mon Dec 21 23:09:48 +0000 2020',\n",
              " 'Mon Dec 21 22:39:54 +0000 2020',\n",
              " 'Mon Dec 21 22:18:29 +0000 2020',\n",
              " 'Mon Dec 21 22:15:52 +0000 2020',\n",
              " 'Mon Dec 21 22:07:21 +0000 2020',\n",
              " 'Mon Dec 21 21:42:32 +0000 2020',\n",
              " 'Mon Dec 21 21:27:06 +0000 2020',\n",
              " 'Mon Dec 21 21:17:01 +0000 2020',\n",
              " 'Mon Dec 21 20:41:18 +0000 2020',\n",
              " 'Mon Dec 21 19:05:00 +0000 2020',\n",
              " 'Mon Dec 21 18:01:10 +0000 2020',\n",
              " 'Mon Dec 21 17:37:37 +0000 2020',\n",
              " 'Mon Dec 21 17:37:24 +0000 2020',\n",
              " 'Mon Dec 21 17:37:05 +0000 2020',\n",
              " 'Mon Dec 21 17:36:45 +0000 2020',\n",
              " 'Mon Dec 21 17:36:25 +0000 2020',\n",
              " 'Mon Dec 21 17:36:12 +0000 2020',\n",
              " 'Mon Dec 21 17:36:01 +0000 2020',\n",
              " 'Mon Dec 21 17:35:44 +0000 2020',\n",
              " 'Mon Dec 21 17:35:33 +0000 2020',\n",
              " 'Mon Dec 21 17:35:21 +0000 2020',\n",
              " 'Mon Dec 21 17:35:08 +0000 2020',\n",
              " 'Mon Dec 21 17:34:56 +0000 2020',\n",
              " 'Mon Dec 21 17:34:45 +0000 2020',\n",
              " 'Mon Dec 21 17:34:32 +0000 2020',\n",
              " 'Mon Dec 21 17:34:18 +0000 2020',\n",
              " 'Mon Dec 21 17:34:05 +0000 2020',\n",
              " 'Mon Dec 21 17:33:50 +0000 2020',\n",
              " 'Mon Dec 21 17:33:30 +0000 2020',\n",
              " 'Mon Dec 21 17:32:39 +0000 2020',\n",
              " 'Mon Dec 21 17:30:52 +0000 2020',\n",
              " 'Mon Dec 21 17:30:43 +0000 2020',\n",
              " 'Mon Dec 21 02:03:02 +0000 2020',\n",
              " 'Mon Dec 21 00:42:02 +0000 2020',\n",
              " 'Sun Dec 20 21:32:56 +0000 2020',\n",
              " 'Sun Dec 20 20:06:01 +0000 2020',\n",
              " 'Sat Dec 19 22:16:00 +0000 2020',\n",
              " 'Sat Dec 19 20:06:27 +0000 2020',\n",
              " 'Sat Dec 19 17:08:00 +0000 2020',\n",
              " 'Sat Dec 19 00:17:22 +0000 2020',\n",
              " 'Fri Dec 18 22:12:00 +0000 2020',\n",
              " 'Fri Dec 18 21:58:51 +0000 2020',\n",
              " 'Fri Dec 18 20:01:20 +0000 2020',\n",
              " 'Fri Dec 18 19:02:06 +0000 2020',\n",
              " 'Fri Dec 18 18:02:00 +0000 2020',\n",
              " 'Fri Dec 18 16:26:22 +0000 2020',\n",
              " 'Fri Dec 18 14:59:51 +0000 2020',\n",
              " 'Fri Dec 18 00:15:00 +0000 2020',\n",
              " 'Thu Dec 17 22:15:00 +0000 2020',\n",
              " 'Thu Dec 17 21:08:44 +0000 2020',\n",
              " 'Thu Dec 17 20:01:21 +0000 2020',\n",
              " 'Thu Dec 17 19:00:05 +0000 2020',\n",
              " 'Thu Dec 17 18:12:32 +0000 2020',\n",
              " 'Thu Dec 17 16:49:12 +0000 2020',\n",
              " 'Thu Dec 17 15:50:50 +0000 2020',\n",
              " 'Thu Dec 17 00:11:00 +0000 2020',\n",
              " 'Wed Dec 16 22:40:06 +0000 2020',\n",
              " 'Wed Dec 16 20:00:51 +0000 2020',\n",
              " 'Wed Dec 16 19:47:11 +0000 2020',\n",
              " 'Wed Dec 16 19:38:30 +0000 2020',\n",
              " 'Wed Dec 16 19:14:19 +0000 2020',\n",
              " 'Wed Dec 16 15:08:42 +0000 2020',\n",
              " 'Wed Dec 16 01:42:58 +0000 2020',\n",
              " 'Wed Dec 16 01:42:02 +0000 2020',\n",
              " 'Wed Dec 16 00:54:00 +0000 2020',\n",
              " 'Tue Dec 15 23:35:01 +0000 2020',\n",
              " 'Tue Dec 15 21:10:01 +0000 2020',\n",
              " 'Tue Dec 15 20:04:55 +0000 2020',\n",
              " 'Tue Dec 15 19:01:48 +0000 2020',\n",
              " 'Tue Dec 15 16:38:06 +0000 2020',\n",
              " 'Tue Dec 15 16:27:25 +0000 2020',\n",
              " 'Tue Dec 15 14:45:17 +0000 2020',\n",
              " 'Mon Dec 14 22:03:00 +0000 2020',\n",
              " 'Mon Dec 14 21:41:34 +0000 2020',\n",
              " 'Mon Dec 14 19:07:23 +0000 2020',\n",
              " 'Mon Dec 14 16:38:01 +0000 2020',\n",
              " 'Mon Dec 14 15:59:35 +0000 2020',\n",
              " 'Mon Dec 14 15:32:49 +0000 2020',\n",
              " 'Mon Dec 14 14:09:01 +0000 2020',\n",
              " 'Sun Dec 13 20:01:32 +0000 2020',\n",
              " 'Sun Dec 13 18:56:56 +0000 2020',\n",
              " 'Sun Dec 13 17:00:02 +0000 2020',\n",
              " 'Sun Dec 13 00:00:02 +0000 2020',\n",
              " 'Sat Dec 12 20:00:01 +0000 2020',\n",
              " 'Sat Dec 12 17:00:02 +0000 2020',\n",
              " 'Sat Dec 12 16:00:01 +0000 2020',\n",
              " 'Sat Dec 12 02:00:35 +0000 2020',\n",
              " 'Sat Dec 12 01:00:02 +0000 2020',\n",
              " 'Sat Dec 12 00:00:00 +0000 2020',\n",
              " 'Fri Dec 11 23:00:01 +0000 2020',\n",
              " 'Fri Dec 11 20:59:13 +0000 2020',\n",
              " 'Fri Dec 11 18:35:49 +0000 2020',\n",
              " 'Fri Dec 11 18:07:19 +0000 2020',\n",
              " 'Fri Dec 11 17:04:32 +0000 2020',\n",
              " 'Fri Dec 11 16:18:58 +0000 2020',\n",
              " 'Fri Dec 11 01:03:01 +0000 2020',\n",
              " 'Thu Dec 10 23:10:14 +0000 2020',\n",
              " 'Thu Dec 10 21:35:00 +0000 2020',\n",
              " 'Thu Dec 10 20:08:18 +0000 2020',\n",
              " 'Thu Dec 10 19:40:44 +0000 2020',\n",
              " 'Thu Dec 10 18:35:00 +0000 2020',\n",
              " 'Thu Dec 10 18:17:04 +0000 2020',\n",
              " 'Thu Dec 10 17:02:54 +0000 2020',\n",
              " 'Thu Dec 10 16:42:09 +0000 2020',\n",
              " 'Thu Dec 10 16:16:12 +0000 2020',\n",
              " 'Thu Dec 10 16:03:00 +0000 2020',\n",
              " 'Thu Dec 10 15:03:58 +0000 2020',\n",
              " 'Wed Dec 09 23:42:55 +0000 2020',\n",
              " 'Wed Dec 09 23:25:00 +0000 2020',\n",
              " 'Wed Dec 09 21:56:07 +0000 2020',\n",
              " 'Wed Dec 09 21:33:58 +0000 2020',\n",
              " 'Wed Dec 09 21:13:23 +0000 2020',\n",
              " 'Wed Dec 09 20:47:15 +0000 2020',\n",
              " 'Wed Dec 09 20:23:48 +0000 2020',\n",
              " 'Wed Dec 09 20:12:45 +0000 2020',\n",
              " 'Wed Dec 09 20:06:58 +0000 2020',\n",
              " 'Wed Dec 09 19:55:12 +0000 2020',\n",
              " 'Wed Dec 09 19:41:26 +0000 2020',\n",
              " 'Wed Dec 09 18:42:37 +0000 2020',\n",
              " 'Wed Dec 09 18:23:01 +0000 2020',\n",
              " 'Wed Dec 09 18:15:56 +0000 2020',\n",
              " 'Wed Dec 09 17:39:45 +0000 2020',\n",
              " 'Wed Dec 09 15:17:26 +0000 2020',\n",
              " 'Wed Dec 09 01:05:06 +0000 2020',\n",
              " 'Tue Dec 08 23:10:00 +0000 2020',\n",
              " 'Tue Dec 08 20:55:01 +0000 2020',\n",
              " 'Tue Dec 08 19:45:03 +0000 2020',\n",
              " 'Tue Dec 08 18:06:31 +0000 2020',\n",
              " 'Tue Dec 08 17:02:18 +0000 2020',\n",
              " 'Tue Dec 08 16:08:49 +0000 2020',\n",
              " 'Tue Dec 08 15:20:06 +0000 2020',\n",
              " 'Tue Dec 08 04:54:14 +0000 2020',\n",
              " 'Tue Dec 08 00:24:00 +0000 2020',\n",
              " 'Mon Dec 07 22:02:06 +0000 2020',\n",
              " 'Mon Dec 07 21:17:07 +0000 2020',\n",
              " 'Mon Dec 07 20:45:01 +0000 2020',\n",
              " 'Mon Dec 07 19:07:37 +0000 2020',\n",
              " 'Mon Dec 07 18:48:46 +0000 2020',\n",
              " 'Mon Dec 07 18:31:01 +0000 2020',\n",
              " 'Mon Dec 07 18:22:43 +0000 2020',\n",
              " 'Mon Dec 07 18:15:48 +0000 2020',\n",
              " 'Mon Dec 07 18:03:10 +0000 2020',\n",
              " 'Mon Dec 07 17:43:30 +0000 2020',\n",
              " 'Mon Dec 07 17:23:50 +0000 2020',\n",
              " 'Mon Dec 07 17:07:11 +0000 2020',\n",
              " 'Mon Dec 07 16:43:27 +0000 2020',\n",
              " 'Mon Dec 07 16:30:48 +0000 2020',\n",
              " 'Mon Dec 07 15:43:08 +0000 2020',\n",
              " 'Mon Dec 07 15:21:39 +0000 2020',\n",
              " 'Mon Dec 07 14:19:37 +0000 2020',\n",
              " 'Mon Dec 07 13:44:22 +0000 2020',\n",
              " 'Sun Dec 06 18:13:18 +0000 2020',\n",
              " 'Sun Dec 06 17:29:30 +0000 2020',\n",
              " 'Sun Dec 06 17:24:00 +0000 2020',\n",
              " 'Sun Dec 06 16:53:15 +0000 2020',\n",
              " 'Sun Dec 06 16:21:12 +0000 2020',\n",
              " 'Sun Dec 06 16:20:43 +0000 2020',\n",
              " 'Sun Dec 06 15:52:15 +0000 2020',\n",
              " 'Sun Dec 06 15:46:04 +0000 2020',\n",
              " 'Sun Dec 06 14:24:28 +0000 2020',\n",
              " 'Sun Dec 06 02:41:15 +0000 2020',\n",
              " 'Sun Dec 06 02:15:27 +0000 2020',\n",
              " 'Sat Dec 05 22:50:12 +0000 2020',\n",
              " 'Sat Dec 05 22:28:07 +0000 2020',\n",
              " 'Sat Dec 05 18:50:53 +0000 2020',\n",
              " 'Sat Dec 05 15:45:00 +0000 2020',\n",
              " 'Sat Dec 05 12:46:47 +0000 2020',\n",
              " 'Sat Dec 05 01:28:13 +0000 2020',\n",
              " 'Fri Dec 04 23:56:56 +0000 2020',\n",
              " 'Fri Dec 04 22:49:01 +0000 2020',\n",
              " 'Fri Dec 04 22:01:29 +0000 2020',\n",
              " 'Fri Dec 04 21:44:53 +0000 2020',\n",
              " 'Fri Dec 04 21:36:44 +0000 2020',\n",
              " 'Fri Dec 04 21:28:34 +0000 2020',\n",
              " 'Fri Dec 04 21:17:10 +0000 2020',\n",
              " 'Fri Dec 04 21:14:08 +0000 2020',\n",
              " 'Fri Dec 04 21:02:53 +0000 2020',\n",
              " 'Fri Dec 04 20:30:01 +0000 2020',\n",
              " 'Fri Dec 04 20:10:00 +0000 2020',\n",
              " 'Fri Dec 04 19:59:30 +0000 2020',\n",
              " 'Fri Dec 04 19:53:53 +0000 2020',\n",
              " 'Fri Dec 04 19:25:30 +0000 2020',\n",
              " 'Fri Dec 04 18:00:02 +0000 2020',\n",
              " 'Fri Dec 04 16:41:41 +0000 2020',\n",
              " 'Fri Dec 04 16:11:15 +0000 2020',\n",
              " 'Fri Dec 04 04:39:10 +0000 2020',\n",
              " 'Fri Dec 04 00:02:00 +0000 2020',\n",
              " 'Thu Dec 03 22:30:34 +0000 2020',\n",
              " 'Thu Dec 03 21:26:44 +0000 2020',\n",
              " 'Thu Dec 03 20:01:41 +0000 2020',\n",
              " 'Thu Dec 03 19:40:00 +0000 2020',\n",
              " 'Thu Dec 03 19:30:13 +0000 2020',\n",
              " 'Thu Dec 03 19:00:15 +0000 2020',\n",
              " 'Thu Dec 03 18:07:35 +0000 2020',\n",
              " 'Thu Dec 03 17:25:42 +0000 2020',\n",
              " 'Thu Dec 03 17:06:39 +0000 2020',\n",
              " 'Thu Dec 03 16:19:22 +0000 2020',\n",
              " 'Thu Dec 03 16:05:01 +0000 2020',\n",
              " 'Thu Dec 03 15:42:16 +0000 2020',\n",
              " 'Thu Dec 03 14:38:54 +0000 2020',\n",
              " 'Thu Dec 03 00:57:00 +0000 2020',\n",
              " 'Wed Dec 02 23:10:00 +0000 2020',\n",
              " 'Wed Dec 02 20:55:06 +0000 2020',\n",
              " 'Wed Dec 02 20:22:02 +0000 2020',\n",
              " 'Wed Dec 02 19:59:06 +0000 2020',\n",
              " 'Wed Dec 02 19:11:30 +0000 2020',\n",
              " 'Wed Dec 02 18:45:21 +0000 2020',\n",
              " 'Wed Dec 02 17:24:05 +0000 2020',\n",
              " 'Wed Dec 02 16:50:38 +0000 2020',\n",
              " 'Wed Dec 02 00:56:01 +0000 2020',\n",
              " 'Tue Dec 01 23:43:01 +0000 2020',\n",
              " 'Tue Dec 01 22:04:35 +0000 2020',\n",
              " 'Tue Dec 01 15:40:01 +0000 2020',\n",
              " 'Tue Dec 01 01:31:00 +0000 2020',\n",
              " 'Mon Nov 30 23:45:03 +0000 2020',\n",
              " 'Mon Nov 30 23:12:57 +0000 2020',\n",
              " 'Mon Nov 30 21:39:02 +0000 2020',\n",
              " 'Mon Nov 30 19:44:15 +0000 2020',\n",
              " 'Mon Nov 30 16:21:51 +0000 2020',\n",
              " 'Sun Nov 29 23:35:06 +0000 2020',\n",
              " 'Sun Nov 29 23:34:37 +0000 2020',\n",
              " 'Sun Nov 29 20:39:02 +0000 2020',\n",
              " 'Sun Nov 29 16:55:58 +0000 2020',\n",
              " 'Sat Nov 28 21:14:06 +0000 2020',\n",
              " 'Sat Nov 28 19:58:19 +0000 2020',\n",
              " 'Sat Nov 28 19:42:16 +0000 2020',\n",
              " 'Sat Nov 28 17:58:41 +0000 2020',\n",
              " 'Sat Nov 28 17:14:44 +0000 2020',\n",
              " 'Sat Nov 28 14:20:12 +0000 2020',\n",
              " 'Sat Nov 28 03:46:01 +0000 2020',\n",
              " 'Sat Nov 28 03:01:07 +0000 2020',\n",
              " 'Sat Nov 28 02:09:06 +0000 2020',\n",
              " 'Sat Nov 28 00:07:01 +0000 2020',\n",
              " 'Fri Nov 27 22:05:06 +0000 2020',\n",
              " 'Fri Nov 27 20:03:01 +0000 2020',\n",
              " 'Fri Nov 27 19:02:00 +0000 2020',\n",
              " 'Fri Nov 27 17:45:01 +0000 2020',\n",
              " 'Fri Nov 27 17:04:43 +0000 2020',\n",
              " 'Fri Nov 27 16:29:21 +0000 2020',\n",
              " 'Fri Nov 27 15:20:49 +0000 2020',\n",
              " 'Fri Nov 27 15:19:54 +0000 2020',\n",
              " 'Fri Nov 27 15:15:17 +0000 2020',\n",
              " 'Fri Nov 27 13:49:17 +0000 2020',\n",
              " 'Fri Nov 27 02:47:52 +0000 2020',\n",
              " 'Thu Nov 26 23:34:01 +0000 2020',\n",
              " 'Thu Nov 26 22:35:08 +0000 2020',\n",
              " 'Thu Nov 26 20:39:29 +0000 2020',\n",
              " 'Thu Nov 26 18:45:36 +0000 2020',\n",
              " 'Thu Nov 26 16:54:06 +0000 2020',\n",
              " 'Thu Nov 26 16:46:44 +0000 2020',\n",
              " 'Wed Nov 25 21:18:40 +0000 2020',\n",
              " 'Wed Nov 25 19:09:52 +0000 2020',\n",
              " 'Wed Nov 25 15:58:32 +0000 2020',\n",
              " 'Wed Nov 25 15:04:32 +0000 2020',\n",
              " 'Wed Nov 25 01:02:00 +0000 2020',\n",
              " 'Tue Nov 24 23:24:00 +0000 2020',\n",
              " 'Tue Nov 24 21:34:01 +0000 2020',\n",
              " 'Tue Nov 24 21:04:26 +0000 2020',\n",
              " 'Tue Nov 24 20:00:53 +0000 2020',\n",
              " 'Tue Nov 24 19:36:49 +0000 2020',\n",
              " 'Tue Nov 24 19:03:11 +0000 2020',\n",
              " 'Tue Nov 24 18:25:05 +0000 2020',\n",
              " 'Tue Nov 24 15:58:00 +0000 2020',\n",
              " 'Tue Nov 24 02:55:00 +0000 2020',\n",
              " 'Mon Nov 23 22:51:54 +0000 2020',\n",
              " 'Mon Nov 23 22:26:08 +0000 2020',\n",
              " 'Mon Nov 23 20:56:56 +0000 2020',\n",
              " 'Mon Nov 23 20:56:11 +0000 2020',\n",
              " 'Mon Nov 23 20:43:36 +0000 2020',\n",
              " 'Mon Nov 23 20:30:01 +0000 2020',\n",
              " 'Mon Nov 23 18:57:45 +0000 2020',\n",
              " 'Mon Nov 23 18:15:46 +0000 2020',\n",
              " 'Mon Nov 23 16:35:34 +0000 2020',\n",
              " 'Sun Nov 22 23:50:07 +0000 2020',\n",
              " 'Sun Nov 22 21:05:07 +0000 2020',\n",
              " 'Sun Nov 22 19:35:01 +0000 2020',\n",
              " 'Sun Nov 22 19:06:14 +0000 2020',\n",
              " 'Sun Nov 22 03:06:20 +0000 2020',\n",
              " 'Sat Nov 21 23:30:05 +0000 2020',\n",
              " 'Sat Nov 21 23:05:00 +0000 2020',\n",
              " 'Sat Nov 21 20:20:01 +0000 2020',\n",
              " 'Sat Nov 21 19:26:11 +0000 2020',\n",
              " 'Sat Nov 21 18:57:59 +0000 2020',\n",
              " 'Sat Nov 21 18:57:54 +0000 2020',\n",
              " 'Sat Nov 21 18:53:17 +0000 2020',\n",
              " 'Sat Nov 21 18:50:15 +0000 2020',\n",
              " 'Sat Nov 21 18:47:37 +0000 2020',\n",
              " 'Sat Nov 21 18:36:35 +0000 2020',\n",
              " 'Sat Nov 21 18:22:49 +0000 2020',\n",
              " 'Sat Nov 21 18:18:12 +0000 2020',\n",
              " 'Sat Nov 21 18:04:15 +0000 2020',\n",
              " 'Sat Nov 21 18:01:50 +0000 2020',\n",
              " 'Sat Nov 21 17:52:41 +0000 2020',\n",
              " 'Sat Nov 21 17:50:14 +0000 2020',\n",
              " 'Sat Nov 21 17:47:53 +0000 2020',\n",
              " 'Sat Nov 21 17:46:44 +0000 2020',\n",
              " 'Sat Nov 21 17:45:18 +0000 2020',\n",
              " 'Sat Nov 21 17:38:26 +0000 2020',\n",
              " 'Sat Nov 21 17:27:59 +0000 2020',\n",
              " 'Sat Nov 21 17:23:53 +0000 2020',\n",
              " 'Sat Nov 21 17:19:21 +0000 2020',\n",
              " 'Sat Nov 21 17:16:03 +0000 2020',\n",
              " 'Sat Nov 21 17:15:32 +0000 2020',\n",
              " 'Sat Nov 21 17:14:41 +0000 2020',\n",
              " 'Sat Nov 21 17:06:21 +0000 2020',\n",
              " 'Sat Nov 21 17:04:09 +0000 2020',\n",
              " 'Sat Nov 21 17:02:22 +0000 2020',\n",
              " 'Sat Nov 21 16:55:40 +0000 2020',\n",
              " 'Sat Nov 21 16:53:42 +0000 2020',\n",
              " 'Sat Nov 21 16:50:13 +0000 2020',\n",
              " 'Sat Nov 21 16:46:00 +0000 2020',\n",
              " 'Sat Nov 21 16:21:45 +0000 2020',\n",
              " 'Sat Nov 21 15:44:16 +0000 2020',\n",
              " 'Sat Nov 21 15:07:16 +0000 2020',\n",
              " 'Sat Nov 21 13:26:51 +0000 2020',\n",
              " 'Sat Nov 21 02:55:43 +0000 2020',\n",
              " 'Sat Nov 21 00:31:08 +0000 2020',\n",
              " 'Fri Nov 20 22:28:06 +0000 2020',\n",
              " 'Fri Nov 20 22:16:54 +0000 2020',\n",
              " 'Fri Nov 20 22:03:38 +0000 2020',\n",
              " 'Fri Nov 20 21:37:16 +0000 2020',\n",
              " 'Fri Nov 20 21:04:15 +0000 2020',\n",
              " 'Fri Nov 20 20:50:59 +0000 2020',\n",
              " 'Fri Nov 20 20:40:42 +0000 2020',\n",
              " 'Fri Nov 20 20:31:14 +0000 2020',\n",
              " 'Fri Nov 20 19:36:08 +0000 2020',\n",
              " 'Fri Nov 20 18:01:05 +0000 2020',\n",
              " 'Fri Nov 20 17:03:16 +0000 2020',\n",
              " 'Fri Nov 20 14:53:25 +0000 2020',\n",
              " 'Fri Nov 20 01:05:06 +0000 2020',\n",
              " 'Thu Nov 19 22:15:07 +0000 2020',\n",
              " 'Thu Nov 19 20:20:06 +0000 2020',\n",
              " 'Thu Nov 19 19:43:01 +0000 2020',\n",
              " 'Thu Nov 19 18:45:03 +0000 2020',\n",
              " 'Thu Nov 19 18:40:17 +0000 2020',\n",
              " 'Thu Nov 19 16:50:24 +0000 2020',\n",
              " 'Thu Nov 19 15:45:31 +0000 2020',\n",
              " 'Thu Nov 19 15:35:40 +0000 2020',\n",
              " 'Thu Nov 19 15:23:33 +0000 2020',\n",
              " 'Thu Nov 19 15:19:41 +0000 2020',\n",
              " 'Thu Nov 19 15:13:28 +0000 2020',\n",
              " 'Thu Nov 19 14:57:56 +0000 2020',\n",
              " 'Thu Nov 19 14:27:59 +0000 2020',\n",
              " 'Thu Nov 19 01:07:00 +0000 2020',\n",
              " 'Thu Nov 19 00:15:07 +0000 2020',\n",
              " 'Wed Nov 18 23:15:06 +0000 2020',\n",
              " 'Wed Nov 18 22:16:30 +0000 2020',\n",
              " 'Wed Nov 18 21:07:26 +0000 2020',\n",
              " 'Wed Nov 18 19:50:01 +0000 2020',\n",
              " 'Wed Nov 18 18:00:02 +0000 2020',\n",
              " 'Wed Nov 18 17:33:31 +0000 2020',\n",
              " 'Wed Nov 18 17:31:00 +0000 2020',\n",
              " 'Wed Nov 18 16:27:22 +0000 2020',\n",
              " 'Wed Nov 18 16:17:46 +0000 2020',\n",
              " 'Wed Nov 18 15:25:51 +0000 2020',\n",
              " 'Wed Nov 18 14:27:43 +0000 2020',\n",
              " 'Wed Nov 18 13:59:09 +0000 2020',\n",
              " 'Wed Nov 18 13:48:24 +0000 2020',\n",
              " 'Wed Nov 18 13:30:18 +0000 2020',\n",
              " 'Wed Nov 18 13:00:08 +0000 2020',\n",
              " 'Wed Nov 18 02:20:00 +0000 2020',\n",
              " 'Wed Nov 18 01:10:06 +0000 2020',\n",
              " 'Wed Nov 18 00:10:00 +0000 2020',\n",
              " 'Tue Nov 17 22:57:33 +0000 2020',\n",
              " 'Tue Nov 17 22:23:35 +0000 2020',\n",
              " 'Tue Nov 17 20:46:00 +0000 2020',\n",
              " 'Tue Nov 17 20:12:29 +0000 2020',\n",
              " 'Tue Nov 17 17:59:06 +0000 2020',\n",
              " 'Tue Nov 17 17:31:34 +0000 2020',\n",
              " 'Tue Nov 17 16:29:20 +0000 2020',\n",
              " 'Tue Nov 17 16:09:30 +0000 2020',\n",
              " 'Tue Nov 17 16:01:19 +0000 2020',\n",
              " 'Tue Nov 17 15:57:56 +0000 2020',\n",
              " 'Tue Nov 17 07:17:29 +0000 2020',\n",
              " 'Tue Nov 17 07:02:28 +0000 2020',\n",
              " 'Tue Nov 17 06:57:11 +0000 2020',\n",
              " 'Tue Nov 17 06:18:52 +0000 2020',\n",
              " 'Tue Nov 17 06:12:33 +0000 2020',\n",
              " 'Tue Nov 17 06:10:29 +0000 2020',\n",
              " 'Tue Nov 17 06:03:14 +0000 2020',\n",
              " 'Tue Nov 17 05:55:27 +0000 2020',\n",
              " 'Tue Nov 17 05:52:24 +0000 2020',\n",
              " 'Tue Nov 17 05:46:48 +0000 2020',\n",
              " 'Tue Nov 17 05:35:11 +0000 2020',\n",
              " 'Tue Nov 17 05:05:01 +0000 2020',\n",
              " 'Tue Nov 17 04:53:41 +0000 2020',\n",
              " 'Tue Nov 17 04:32:18 +0000 2020',\n",
              " 'Tue Nov 17 04:31:23 +0000 2020',\n",
              " 'Tue Nov 17 04:30:16 +0000 2020',\n",
              " 'Tue Nov 17 04:20:56 +0000 2020',\n",
              " 'Tue Nov 17 04:16:56 +0000 2020',\n",
              " 'Tue Nov 17 04:14:10 +0000 2020',\n",
              " 'Tue Nov 17 04:12:26 +0000 2020',\n",
              " 'Tue Nov 17 04:05:25 +0000 2020',\n",
              " 'Tue Nov 17 04:01:56 +0000 2020',\n",
              " 'Tue Nov 17 03:59:49 +0000 2020',\n",
              " 'Tue Nov 17 03:58:12 +0000 2020',\n",
              " 'Tue Nov 17 03:57:27 +0000 2020',\n",
              " 'Tue Nov 17 03:54:57 +0000 2020',\n",
              " 'Tue Nov 17 03:49:46 +0000 2020',\n",
              " 'Tue Nov 17 03:45:43 +0000 2020',\n",
              " 'Tue Nov 17 03:40:11 +0000 2020',\n",
              " 'Tue Nov 17 03:30:10 +0000 2020',\n",
              " 'Tue Nov 17 03:12:26 +0000 2020',\n",
              " 'Tue Nov 17 03:07:21 +0000 2020',\n",
              " 'Tue Nov 17 01:32:23 +0000 2020',\n",
              " 'Mon Nov 16 23:01:34 +0000 2020',\n",
              " 'Mon Nov 16 22:55:03 +0000 2020',\n",
              " 'Mon Nov 16 22:34:37 +0000 2020',\n",
              " 'Mon Nov 16 22:28:56 +0000 2020',\n",
              " 'Mon Nov 16 22:12:44 +0000 2020',\n",
              " 'Mon Nov 16 22:07:40 +0000 2020',\n",
              " 'Mon Nov 16 21:58:21 +0000 2020',\n",
              " 'Mon Nov 16 21:48:38 +0000 2020',\n",
              " 'Mon Nov 16 21:18:15 +0000 2020',\n",
              " 'Mon Nov 16 20:42:08 +0000 2020',\n",
              " 'Mon Nov 16 19:40:01 +0000 2020',\n",
              " 'Mon Nov 16 18:25:07 +0000 2020',\n",
              " 'Mon Nov 16 17:56:40 +0000 2020',\n",
              " 'Mon Nov 16 17:05:03 +0000 2020',\n",
              " 'Mon Nov 16 16:35:05 +0000 2020',\n",
              " 'Mon Nov 16 14:34:42 +0000 2020',\n",
              " 'Mon Nov 16 14:00:22 +0000 2020',\n",
              " 'Mon Nov 16 10:22:51 +0000 2020',\n",
              " 'Mon Nov 16 06:30:01 +0000 2020',\n",
              " 'Mon Nov 16 06:02:13 +0000 2020',\n",
              " 'Mon Nov 16 05:38:48 +0000 2020',\n",
              " 'Mon Nov 16 05:11:46 +0000 2020',\n",
              " 'Mon Nov 16 04:40:07 +0000 2020',\n",
              " 'Mon Nov 16 04:08:05 +0000 2020',\n",
              " 'Mon Nov 16 03:47:29 +0000 2020',\n",
              " 'Mon Nov 16 03:18:07 +0000 2020',\n",
              " 'Mon Nov 16 03:03:02 +0000 2020',\n",
              " 'Mon Nov 16 02:57:03 +0000 2020',\n",
              " 'Mon Nov 16 02:40:56 +0000 2020',\n",
              " 'Mon Nov 16 02:38:11 +0000 2020',\n",
              " 'Mon Nov 16 02:38:11 +0000 2020',\n",
              " 'Mon Nov 16 02:37:37 +0000 2020',\n",
              " 'Mon Nov 16 02:36:44 +0000 2020',\n",
              " 'Mon Nov 16 02:34:04 +0000 2020',\n",
              " 'Mon Nov 16 02:34:02 +0000 2020',\n",
              " 'Mon Nov 16 02:32:58 +0000 2020',\n",
              " 'Mon Nov 16 02:30:53 +0000 2020',\n",
              " 'Mon Nov 16 02:25:16 +0000 2020',\n",
              " 'Mon Nov 16 02:21:07 +0000 2020',\n",
              " 'Mon Nov 16 02:19:11 +0000 2020',\n",
              " 'Mon Nov 16 02:18:07 +0000 2020',\n",
              " 'Mon Nov 16 02:17:16 +0000 2020',\n",
              " 'Mon Nov 16 02:12:53 +0000 2020',\n",
              " 'Mon Nov 16 02:03:56 +0000 2020',\n",
              " 'Mon Nov 16 01:42:59 +0000 2020',\n",
              " 'Mon Nov 16 01:29:42 +0000 2020',\n",
              " 'Mon Nov 16 01:12:58 +0000 2020',\n",
              " 'Mon Nov 16 01:12:12 +0000 2020',\n",
              " 'Mon Nov 16 01:05:17 +0000 2020',\n",
              " 'Mon Nov 16 01:00:57 +0000 2020',\n",
              " 'Mon Nov 16 01:00:43 +0000 2020',\n",
              " 'Mon Nov 16 00:55:56 +0000 2020',\n",
              " 'Mon Nov 16 00:52:46 +0000 2020',\n",
              " 'Mon Nov 16 00:51:30 +0000 2020',\n",
              " 'Mon Nov 16 00:48:22 +0000 2020',\n",
              " 'Mon Nov 16 00:46:06 +0000 2020',\n",
              " 'Mon Nov 16 00:45:34 +0000 2020',\n",
              " 'Mon Nov 16 00:41:30 +0000 2020',\n",
              " 'Mon Nov 16 00:41:00 +0000 2020',\n",
              " 'Mon Nov 16 00:40:26 +0000 2020',\n",
              " 'Mon Nov 16 00:39:54 +0000 2020',\n",
              " 'Mon Nov 16 00:39:13 +0000 2020',\n",
              " 'Mon Nov 16 00:37:12 +0000 2020',\n",
              " 'Mon Nov 16 00:32:52 +0000 2020',\n",
              " 'Mon Nov 16 00:30:23 +0000 2020',\n",
              " 'Mon Nov 16 00:25:45 +0000 2020',\n",
              " 'Mon Nov 16 00:25:32 +0000 2020',\n",
              " 'Mon Nov 16 00:16:36 +0000 2020',\n",
              " 'Mon Nov 16 00:13:06 +0000 2020',\n",
              " 'Mon Nov 16 00:03:40 +0000 2020',\n",
              " 'Sun Nov 15 23:54:56 +0000 2020',\n",
              " 'Sun Nov 15 23:50:06 +0000 2020',\n",
              " 'Sun Nov 15 23:46:53 +0000 2020',\n",
              " 'Sun Nov 15 23:29:20 +0000 2020',\n",
              " 'Sun Nov 15 23:22:24 +0000 2020',\n",
              " 'Sun Nov 15 23:20:32 +0000 2020',\n",
              " 'Sun Nov 15 23:15:42 +0000 2020',\n",
              " 'Sun Nov 15 23:15:15 +0000 2020',\n",
              " 'Sun Nov 15 23:03:22 +0000 2020',\n",
              " 'Sun Nov 15 22:47:14 +0000 2020',\n",
              " 'Sun Nov 15 22:44:29 +0000 2020',\n",
              " 'Sun Nov 15 22:38:47 +0000 2020',\n",
              " 'Sun Nov 15 22:30:44 +0000 2020',\n",
              " 'Sun Nov 15 22:26:54 +0000 2020',\n",
              " 'Sun Nov 15 22:17:22 +0000 2020',\n",
              " 'Sun Nov 15 22:13:23 +0000 2020',\n",
              " 'Sun Nov 15 21:55:57 +0000 2020',\n",
              " 'Sun Nov 15 21:53:54 +0000 2020',\n",
              " 'Sun Nov 15 21:52:38 +0000 2020',\n",
              " 'Sun Nov 15 21:49:16 +0000 2020',\n",
              " 'Sun Nov 15 21:42:11 +0000 2020',\n",
              " 'Sun Nov 15 21:38:21 +0000 2020',\n",
              " 'Sun Nov 15 21:33:01 +0000 2020',\n",
              " 'Sun Nov 15 21:30:29 +0000 2020',\n",
              " 'Sun Nov 15 21:16:50 +0000 2020',\n",
              " 'Sun Nov 15 21:13:53 +0000 2020',\n",
              " 'Sun Nov 15 21:11:23 +0000 2020',\n",
              " 'Sun Nov 15 21:09:51 +0000 2020',\n",
              " 'Sun Nov 15 21:04:55 +0000 2020',\n",
              " 'Sun Nov 15 21:02:16 +0000 2020',\n",
              " 'Sun Nov 15 20:39:12 +0000 2020',\n",
              " 'Sun Nov 15 20:37:54 +0000 2020',\n",
              " 'Sun Nov 15 20:36:17 +0000 2020',\n",
              " 'Sun Nov 15 20:29:18 +0000 2020',\n",
              " 'Sun Nov 15 20:15:51 +0000 2020',\n",
              " 'Sun Nov 15 19:48:25 +0000 2020',\n",
              " 'Sun Nov 15 19:20:32 +0000 2020',\n",
              " 'Sun Nov 15 19:02:01 +0000 2020',\n",
              " 'Sun Nov 15 18:00:12 +0000 2020',\n",
              " 'Sun Nov 15 17:15:03 +0000 2020',\n",
              " 'Sun Nov 15 16:30:27 +0000 2020',\n",
              " 'Sun Nov 15 16:01:40 +0000 2020',\n",
              " 'Sun Nov 15 14:58:32 +0000 2020',\n",
              " 'Sun Nov 15 14:54:37 +0000 2020',\n",
              " 'Sun Nov 15 13:22:49 +0000 2020',\n",
              " 'Sun Nov 15 13:10:48 +0000 2020',\n",
              " 'Sun Nov 15 04:06:00 +0000 2020',\n",
              " 'Sun Nov 15 02:32:00 +0000 2020',\n",
              " 'Sun Nov 15 00:44:35 +0000 2020',\n",
              " 'Sat Nov 14 20:39:11 +0000 2020',\n",
              " 'Sat Nov 14 20:04:06 +0000 2020',\n",
              " 'Sat Nov 14 19:10:37 +0000 2020',\n",
              " 'Sat Nov 14 18:41:34 +0000 2020',\n",
              " 'Sat Nov 14 18:27:38 +0000 2020',\n",
              " 'Sat Nov 14 17:32:00 +0000 2020',\n",
              " 'Sat Nov 14 15:22:50 +0000 2020',\n",
              " 'Sat Nov 14 15:11:15 +0000 2020',\n",
              " 'Sat Nov 14 13:58:00 +0000 2020',\n",
              " 'Sat Nov 14 02:06:32 +0000 2020',\n",
              " 'Sat Nov 14 00:50:06 +0000 2020',\n",
              " 'Fri Nov 13 23:37:29 +0000 2020',\n",
              " 'Fri Nov 13 23:36:00 +0000 2020',\n",
              " 'Fri Nov 13 23:22:31 +0000 2020',\n",
              " 'Fri Nov 13 23:13:20 +0000 2020',\n",
              " 'Fri Nov 13 21:10:43 +0000 2020',\n",
              " 'Fri Nov 13 21:06:12 +0000 2020',\n",
              " 'Fri Nov 13 18:59:06 +0000 2020',\n",
              " 'Fri Nov 13 18:43:57 +0000 2020',\n",
              " 'Fri Nov 13 18:30:02 +0000 2020',\n",
              " 'Fri Nov 13 17:50:00 +0000 2020',\n",
              " 'Fri Nov 13 17:04:34 +0000 2020',\n",
              " 'Fri Nov 13 15:37:19 +0000 2020',\n",
              " 'Fri Nov 13 15:27:25 +0000 2020',\n",
              " 'Fri Nov 13 15:21:26 +0000 2020',\n",
              " 'Fri Nov 13 15:12:35 +0000 2020',\n",
              " 'Fri Nov 13 15:00:56 +0000 2020',\n",
              " 'Fri Nov 13 14:14:51 +0000 2020',\n",
              " 'Fri Nov 13 13:54:15 +0000 2020',\n",
              " 'Fri Nov 13 04:12:29 +0000 2020',\n",
              " 'Fri Nov 13 02:00:07 +0000 2020',\n",
              " 'Fri Nov 13 01:07:00 +0000 2020',\n",
              " 'Thu Nov 12 23:29:32 +0000 2020',\n",
              " 'Thu Nov 12 22:12:22 +0000 2020',\n",
              " 'Thu Nov 12 21:46:01 +0000 2020',\n",
              " 'Thu Nov 12 20:00:54 +0000 2020',\n",
              " 'Thu Nov 12 18:23:45 +0000 2020',\n",
              " 'Thu Nov 12 17:59:07 +0000 2020',\n",
              " 'Thu Nov 12 17:49:45 +0000 2020',\n",
              " 'Thu Nov 12 17:20:06 +0000 2020',\n",
              " 'Thu Nov 12 15:41:44 +0000 2020',\n",
              " 'Thu Nov 12 01:10:01 +0000 2020',\n",
              " 'Wed Nov 11 23:42:50 +0000 2020',\n",
              " 'Wed Nov 11 23:37:01 +0000 2020',\n",
              " 'Wed Nov 11 22:15:00 +0000 2020',\n",
              " 'Wed Nov 11 20:27:05 +0000 2020',\n",
              " 'Wed Nov 11 18:55:25 +0000 2020',\n",
              " 'Wed Nov 11 17:01:40 +0000 2020',\n",
              " 'Wed Nov 11 16:10:01 +0000 2020',\n",
              " 'Wed Nov 11 02:05:00 +0000 2020',\n",
              " 'Wed Nov 11 00:55:00 +0000 2020',\n",
              " 'Tue Nov 10 23:26:54 +0000 2020',\n",
              " 'Tue Nov 10 22:22:52 +0000 2020',\n",
              " 'Tue Nov 10 21:15:54 +0000 2020',\n",
              " 'Tue Nov 10 20:45:24 +0000 2020',\n",
              " 'Tue Nov 10 20:31:14 +0000 2020',\n",
              " 'Tue Nov 10 19:50:22 +0000 2020',\n",
              " 'Tue Nov 10 19:17:01 +0000 2020',\n",
              " 'Tue Nov 10 18:55:29 +0000 2020',\n",
              " 'Tue Nov 10 17:28:12 +0000 2020',\n",
              " 'Tue Nov 10 16:45:01 +0000 2020',\n",
              " 'Tue Nov 10 16:22:39 +0000 2020',\n",
              " 'Tue Nov 10 16:01:05 +0000 2020',\n",
              " 'Tue Nov 10 15:04:47 +0000 2020',\n",
              " 'Tue Nov 10 14:49:32 +0000 2020',\n",
              " 'Tue Nov 10 00:36:01 +0000 2020',\n",
              " 'Mon Nov 09 23:46:06 +0000 2020',\n",
              " 'Mon Nov 09 22:57:15 +0000 2020',\n",
              " 'Mon Nov 09 22:05:46 +0000 2020',\n",
              " 'Mon Nov 09 21:45:00 +0000 2020',\n",
              " 'Mon Nov 09 18:44:47 +0000 2020',\n",
              " 'Mon Nov 09 18:40:57 +0000 2020',\n",
              " 'Mon Nov 09 18:24:01 +0000 2020',\n",
              " 'Mon Nov 09 18:16:10 +0000 2020',\n",
              " 'Mon Nov 09 17:13:12 +0000 2020',\n",
              " 'Mon Nov 09 16:49:26 +0000 2020',\n",
              " 'Mon Nov 09 16:32:13 +0000 2020',\n",
              " 'Mon Nov 09 15:56:12 +0000 2020',\n",
              " 'Sun Nov 08 23:08:06 +0000 2020',\n",
              " 'Sun Nov 08 21:24:28 +0000 2020',\n",
              " 'Sun Nov 08 20:30:26 +0000 2020',\n",
              " 'Sun Nov 08 19:50:38 +0000 2020',\n",
              " 'Sun Nov 08 19:33:00 +0000 2020',\n",
              " 'Sun Nov 08 19:24:25 +0000 2020',\n",
              " 'Sun Nov 08 19:20:43 +0000 2020',\n",
              " 'Sun Nov 08 19:18:00 +0000 2020',\n",
              " 'Sun Nov 08 19:14:39 +0000 2020',\n",
              " 'Sun Nov 08 19:10:53 +0000 2020',\n",
              " 'Sun Nov 08 19:05:43 +0000 2020',\n",
              " 'Sun Nov 08 18:57:21 +0000 2020',\n",
              " 'Sun Nov 08 18:45:42 +0000 2020',\n",
              " 'Sun Nov 08 18:15:01 +0000 2020',\n",
              " 'Sun Nov 08 00:07:01 +0000 2020',\n",
              " 'Sat Nov 07 21:21:13 +0000 2020',\n",
              " 'Sat Nov 07 02:03:15 +0000 2020',\n",
              " 'Sat Nov 07 00:06:02 +0000 2020',\n",
              " 'Fri Nov 06 22:08:35 +0000 2020',\n",
              " 'Fri Nov 06 21:55:06 +0000 2020',\n",
              " 'Fri Nov 06 19:36:12 +0000 2020',\n",
              " 'Fri Nov 06 19:04:27 +0000 2020',\n",
              " 'Fri Nov 06 17:56:48 +0000 2020',\n",
              " 'Thu Nov 05 22:31:54 +0000 2020',\n",
              " 'Thu Nov 05 21:52:07 +0000 2020',\n",
              " 'Thu Nov 05 20:51:30 +0000 2020',\n",
              " 'Thu Nov 05 19:45:02 +0000 2020',\n",
              " 'Thu Nov 05 17:15:58 +0000 2020',\n",
              " 'Wed Nov 04 23:56:08 +0000 2020',\n",
              " 'Wed Nov 04 21:57:15 +0000 2020',\n",
              " 'Wed Nov 04 21:20:10 +0000 2020',\n",
              " 'Wed Nov 04 18:55:49 +0000 2020',\n",
              " 'Wed Nov 04 17:58:24 +0000 2020',\n",
              " 'Tue Nov 03 23:45:06 +0000 2020',\n",
              " 'Tue Nov 03 22:05:06 +0000 2020',\n",
              " 'Tue Nov 03 21:24:58 +0000 2020',\n",
              " 'Tue Nov 03 19:29:41 +0000 2020',\n",
              " 'Tue Nov 03 17:37:10 +0000 2020',\n",
              " 'Tue Nov 03 17:26:50 +0000 2020',\n",
              " 'Tue Nov 03 17:21:57 +0000 2020',\n",
              " 'Tue Nov 03 17:20:00 +0000 2020',\n",
              " 'Tue Nov 03 17:10:33 +0000 2020',\n",
              " 'Tue Nov 03 16:51:10 +0000 2020',\n",
              " 'Tue Nov 03 16:10:00 +0000 2020',\n",
              " 'Tue Nov 03 11:55:23 +0000 2020',\n",
              " 'Tue Nov 03 02:55:00 +0000 2020',\n",
              " 'Tue Nov 03 01:50:06 +0000 2020',\n",
              " 'Tue Nov 03 00:40:00 +0000 2020',\n",
              " 'Mon Nov 02 23:35:09 +0000 2020',\n",
              " 'Mon Nov 02 22:33:44 +0000 2020',\n",
              " 'Mon Nov 02 22:21:00 +0000 2020',\n",
              " 'Mon Nov 02 22:00:41 +0000 2020',\n",
              " 'Mon Nov 02 20:01:00 +0000 2020',\n",
              " 'Mon Nov 02 19:05:07 +0000 2020',\n",
              " 'Mon Nov 02 18:22:50 +0000 2020',\n",
              " 'Mon Nov 02 17:41:22 +0000 2020',\n",
              " 'Mon Nov 02 16:19:02 +0000 2020',\n",
              " 'Mon Nov 02 00:48:23 +0000 2020',\n",
              " 'Mon Nov 02 00:21:31 +0000 2020',\n",
              " 'Sun Nov 01 23:56:35 +0000 2020',\n",
              " 'Sun Nov 01 20:03:00 +0000 2020',\n",
              " 'Sun Nov 01 18:09:00 +0000 2020',\n",
              " 'Sat Oct 31 23:16:51 +0000 2020',\n",
              " 'Sat Oct 31 22:02:27 +0000 2020',\n",
              " 'Sat Oct 31 21:30:10 +0000 2020',\n",
              " 'Sat Oct 31 19:00:01 +0000 2020',\n",
              " 'Sat Oct 31 18:03:56 +0000 2020',\n",
              " 'Sat Oct 31 17:34:12 +0000 2020',\n",
              " 'Sat Oct 31 17:03:59 +0000 2020',\n",
              " 'Sat Oct 31 16:56:24 +0000 2020',\n",
              " 'Sat Oct 31 16:53:23 +0000 2020',\n",
              " 'Sat Oct 31 16:05:53 +0000 2020',\n",
              " 'Sat Oct 31 16:05:08 +0000 2020',\n",
              " 'Sat Oct 31 16:04:31 +0000 2020',\n",
              " 'Sat Oct 31 16:03:21 +0000 2020',\n",
              " 'Sat Oct 31 16:02:54 +0000 2020',\n",
              " 'Sat Oct 31 16:02:10 +0000 2020',\n",
              " 'Sat Oct 31 16:00:23 +0000 2020',\n",
              " 'Sat Oct 31 15:51:44 +0000 2020',\n",
              " 'Sat Oct 31 15:00:48 +0000 2020',\n",
              " 'Sat Oct 31 12:37:08 +0000 2020',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2rZxQ21zpio"
      },
      "source": [
        "6\\. Select the first 3 rows from `df`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AUHILnszpio",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "a4c4fabb-4bee-4f48-b275-3a9fab221be0"
      },
      "source": [
        "# Your answer here\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>retweet_created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1354552906175934477</td>\n",
              "      <td>Wed Jan 27 22:12:33 +0000 2021</td>\n",
              "      <td>It once held a lake. And what we're going to do, as soon as we get there, is to explore the rocks that were deposi‚Ä¶ https://t.co/UW9wngvx4C</td>\n",
              "      <td>72</td>\n",
              "      <td>462</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1354549784061865986</td>\n",
              "      <td>Wed Jan 27 22:00:09 +0000 2021</td>\n",
              "      <td>I asked the team [...] to come up with something that would symbolize, to mark this challenge and thank in particu‚Ä¶ https://t.co/QH235r9zjq</td>\n",
              "      <td>50</td>\n",
              "      <td>361</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1354546326139265030</td>\n",
              "      <td>Wed Jan 27 21:46:25 +0000 2021</td>\n",
              "      <td>Perseverance is the very first rover designed to seek signs of past microbial life, by collecting and caching rock‚Ä¶ https://t.co/nn72OHRVv6</td>\n",
              "      <td>135</td>\n",
              "      <td>870</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             status_id  ... retweet_created_at\n",
              "0  1354552906175934477  ...                NaN\n",
              "1  1354549784061865986  ...                NaN\n",
              "2  1354546326139265030  ...                NaN\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eJ5A_Q_zpio"
      },
      "source": [
        "7\\. Select the last 3 rows from `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6zVQPUZzpio",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "453b0926-ec44-4db3-ce37-84fa91d28d33"
      },
      "source": [
        "# Your answer here\n",
        "df.tail(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>retweet_created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3197</th>\n",
              "      <td>1265327291468562432</td>\n",
              "      <td>Tue May 26 17:01:49 +0000 2020</td>\n",
              "      <td>LIVE: Want to go behind-the-scenes of #LaunchAmerica?Join our experts on @reddit to ask questions about the missi‚Ä¶ https://t.co/p7iqJY4jyX</td>\n",
              "      <td>253</td>\n",
              "      <td>1942</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3198</th>\n",
              "      <td>1265327258274840576</td>\n",
              "      <td>Tue May 26 17:01:41 +0000 2020</td>\n",
              "      <td>@brandonleblanc @SpaceX @AmyShiraTeitel See you online! https://t.co/FaQ7K75sBP</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3199</th>\n",
              "      <td>1265317908068085761</td>\n",
              "      <td>Tue May 26 16:24:32 +0000 2020</td>\n",
              "      <td>RT @NASAEarth: Ready to #LaunchAmerica? Tomorrow, two astronauts üë®üèª‚ÄçüöÄüë®üèª‚ÄçüöÄ are launching üöÄ to the @Space_Station from @NASAKennedy‚Äôs histori‚Ä¶</td>\n",
              "      <td>595</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Tue May 26 16:09:54 +0000 2020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                status_id  ...              retweet_created_at\n",
              "3197  1265327291468562432  ...                             NaN\n",
              "3198  1265327258274840576  ...                             NaN\n",
              "3199  1265317908068085761  ...  Tue May 26 16:09:54 +0000 2020\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbkdq5Zozpio"
      },
      "source": [
        "8. Select the element at row index position 999 and in the `text` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B635EUBzpip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "68ddc61f-80e6-4902-be28-ba765cddf92b"
      },
      "source": [
        "# Your answer here\n",
        "df[\"text\"][999]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'RT @NASAMoon: Happy HalloweenüéÉ! A full Moon is always a treat, but this one is a tricksterüëª As the second full Moon in a month, we call i‚Ä¶'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LrHwZOHzpip"
      },
      "source": [
        "9\\. Select the element in the fifth row and the third column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlJcy_7Fzpip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0af4d955-00b4-49db-b8b1-d41aceaeecf7"
      },
      "source": [
        "# Your answer here\n",
        "df.iloc[0, 2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"It once held a lake. And what we're going to do, as soon as we get there, is to explore the rocks that were deposi‚Ä¶ https://t.co/UW9wngvx4C\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSworXtzpip"
      },
      "source": [
        "10\\. Select all values from the last column, without specifying the column label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OsaL7Yozpip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4357b6-9f07-4545-86af-65c5317a0768"
      },
      "source": [
        "# Your answer here\n",
        "df.iloc[:, -1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                  NaN\n",
              "1                                  NaN\n",
              "2                                  NaN\n",
              "3                                  NaN\n",
              "4       Wed Jan 27 20:18:56 +0000 2021\n",
              "                     ...              \n",
              "3195    Tue May 26 19:36:00 +0000 2020\n",
              "3196                               NaN\n",
              "3197                               NaN\n",
              "3198                               NaN\n",
              "3199    Tue May 26 16:09:54 +0000 2020\n",
              "Name: retweet_created_at, Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAANpZwuzpiq"
      },
      "source": [
        "11\\. Select all rows in the last two columns, without specifying the column labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KPs84_8zpiq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c3f4f5fc-5fcd-4411-e156-143c226be9aa"
      },
      "source": [
        "# Your answer here\n",
        "df.iloc[:,-2:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>retweet_created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Wed Jan 27 20:18:56 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3195</th>\n",
              "      <td>1</td>\n",
              "      <td>Tue May 26 19:36:00 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3196</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3197</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3198</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3199</th>\n",
              "      <td>1</td>\n",
              "      <td>Tue May 26 16:09:54 +0000 2020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3200 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      is_retweet              retweet_created_at\n",
              "0              0                             NaN\n",
              "1              0                             NaN\n",
              "2              0                             NaN\n",
              "3              0                             NaN\n",
              "4              1  Wed Jan 27 20:18:56 +0000 2021\n",
              "...          ...                             ...\n",
              "3195           1  Tue May 26 19:36:00 +0000 2020\n",
              "3196           0                             NaN\n",
              "3197           0                             NaN\n",
              "3198           0                             NaN\n",
              "3199           1  Tue May 26 16:09:54 +0000 2020\n",
              "\n",
              "[3200 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TIHKd8szpiq"
      },
      "source": [
        "12\\. Select the first five rows in the last two columns, without specifying the column labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWuCZb31zpiq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "acd8d529-6e94-4430-8475-07c47fc60b27"
      },
      "source": [
        "# Your answer here\n",
        "df.iloc[:5, -2:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>retweet_created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Wed Jan 27 20:18:56 +0000 2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_retweet              retweet_created_at\n",
              "0           0                             NaN\n",
              "1           0                             NaN\n",
              "2           0                             NaN\n",
              "3           0                             NaN\n",
              "4           1  Wed Jan 27 20:18:56 +0000 2021"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U9I2bwhzpiq"
      },
      "source": [
        "13\\. Select all rows from `df` with the `favorite_count` column value being strictly larger than 5000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cfdNm2RZzpiq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b38a66b-41e4-4e02-807f-b4b2f9893361"
      },
      "source": [
        "# Your answer here\n",
        "df[df.favorite_count>5000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>retweet_created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1354376310638977025</td>\n",
              "      <td>Wed Jan 27 10:30:50 +0000 2021</td>\n",
              "      <td>LIVE NOW: Spacewalk with astronauts outside the @Space_Station! Tune in as @AstroVicGlover &amp;amp; @Astro_illini perform‚Ä¶ https://t.co/jen7NICEtb</td>\n",
              "      <td>1664</td>\n",
              "      <td>6522</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1354246577523740674</td>\n",
              "      <td>Wed Jan 27 01:55:19 +0000 2021</td>\n",
              "      <td>Suit up and step out for some Earth views: it's spacewalk time.Watch NASA TV tomorrow starting at 5:30am ET for‚Ä¶ https://t.co/oJsV9bnWbp</td>\n",
              "      <td>817</td>\n",
              "      <td>5443</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1354102852323520513</td>\n",
              "      <td>Tue Jan 26 16:24:12 +0000 2021</td>\n",
              "      <td>üì∏ Just in: new views of our solar system! Our @NASASun missions Parker Solar Probe, and STEREO spacecraft, as well‚Ä¶ https://t.co/MlQJjl5aq1</td>\n",
              "      <td>1052</td>\n",
              "      <td>7241</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>1353431128766603264</td>\n",
              "      <td>Sun Jan 24 19:55:01 +0000 2021</td>\n",
              "      <td>‚ÄúIt‚Äôs heart stopping.‚Äù‚ÄúIt‚Äôs soul pounding.‚Äù ‚ÄúIt‚Äôs breathtaking.‚Äù üòç Take in a new perspective of Earth as seen t‚Ä¶ https://t.co/5YFkFUtTx9</td>\n",
              "      <td>821</td>\n",
              "      <td>5374</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>1353081323578150912</td>\n",
              "      <td>Sat Jan 23 20:45:01 +0000 2021</td>\n",
              "      <td>A galaxy far, far away...50 million light years from Earth, in the constellation of Virgo, the lost galaxy NGC‚Ä¶ https://t.co/skf4JBVol0</td>\n",
              "      <td>2284</td>\n",
              "      <td>15813</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3168</th>\n",
              "      <td>1265655788858748929</td>\n",
              "      <td>Wed May 27 14:47:09 +0000 2020</td>\n",
              "      <td>Welcome to Launch Day üöÄLive #LaunchAmerica coverage starts at 12:15pm ET. Liftoff is at 4:33pm ET. Let‚Äôs light‚Ä¶ https://t.co/lZ2s6vzOXL</td>\n",
              "      <td>7410</td>\n",
              "      <td>20914</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3171</th>\n",
              "      <td>1265643951513624579</td>\n",
              "      <td>Wed May 27 14:00:07 +0000 2020</td>\n",
              "      <td>Meet our special guest host for today's #LaunchAmerica broadcast: @Astro_Flow, who has traveled on two space shuttl‚Ä¶ https://t.co/IiGksHRUmH</td>\n",
              "      <td>1207</td>\n",
              "      <td>9941</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3174</th>\n",
              "      <td>1265577232728285190</td>\n",
              "      <td>Wed May 27 09:35:00 +0000 2020</td>\n",
              "      <td>Our #LaunchAmerica LIVE coverage includes liftoff of @SpaceX‚Äôs Crew Dragon spacecraft, a @KellyClarkson performance‚Ä¶ https://t.co/eYgetZuLmo</td>\n",
              "      <td>3996</td>\n",
              "      <td>11185</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3181</th>\n",
              "      <td>1265478732019650562</td>\n",
              "      <td>Wed May 27 03:03:35 +0000 2020</td>\n",
              "      <td>Together with @SpaceX, we will return human spaceflight to American soil after nearly a decade. Tomorrow is not onl‚Ä¶ https://t.co/64pR7u3bzE</td>\n",
              "      <td>10734</td>\n",
              "      <td>48145</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3194</th>\n",
              "      <td>1265386899197308928</td>\n",
              "      <td>Tue May 26 20:58:41 +0000 2020</td>\n",
              "      <td>Tomorrow, @AstroBehnken &amp;amp; @Astro_Doug become the 1st humans to launch to the @Space_Station from American soil sinc‚Ä¶ https://t.co/FLwTnLSGyA</td>\n",
              "      <td>2428</td>\n",
              "      <td>9297</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>512 rows √ó 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                status_id  ... retweet_created_at\n",
              "32    1354376310638977025  ...                NaN\n",
              "34    1354246577523740674  ...                NaN\n",
              "43    1354102852323520513  ...                NaN\n",
              "52    1353431128766603264  ...                NaN\n",
              "56    1353081323578150912  ...                NaN\n",
              "...                   ...  ...                ...\n",
              "3168  1265655788858748929  ...                NaN\n",
              "3171  1265643951513624579  ...                NaN\n",
              "3174  1265577232728285190  ...                NaN\n",
              "3181  1265478732019650562  ...                NaN\n",
              "3194  1265386899197308928  ...                NaN\n",
              "\n",
              "[512 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynFHYip9zpir"
      },
      "source": [
        "14\\. Select all rows from `df` with the `favorite_count` column value being between 5000 (inclusive) and 10000 (exclusive)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXxoV4zHzpir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b259cdb-b793-4043-8ff8-1586d635b75e"
      },
      "source": [
        "# Your answer here\n",
        "df[(df.favorite_count>=5000) & (df.favorite_count<10000)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>retweet_created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1354376310638977025</td>\n",
              "      <td>Wed Jan 27 10:30:50 +0000 2021</td>\n",
              "      <td>LIVE NOW: Spacewalk with astronauts outside the @Space_Station! Tune in as @AstroVicGlover &amp;amp; @Astro_illini perform‚Ä¶ https://t.co/jen7NICEtb</td>\n",
              "      <td>1664</td>\n",
              "      <td>6522</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1354246577523740674</td>\n",
              "      <td>Wed Jan 27 01:55:19 +0000 2021</td>\n",
              "      <td>Suit up and step out for some Earth views: it's spacewalk time.Watch NASA TV tomorrow starting at 5:30am ET for‚Ä¶ https://t.co/oJsV9bnWbp</td>\n",
              "      <td>817</td>\n",
              "      <td>5443</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1354102852323520513</td>\n",
              "      <td>Tue Jan 26 16:24:12 +0000 2021</td>\n",
              "      <td>üì∏ Just in: new views of our solar system! Our @NASASun missions Parker Solar Probe, and STEREO spacecraft, as well‚Ä¶ https://t.co/MlQJjl5aq1</td>\n",
              "      <td>1052</td>\n",
              "      <td>7241</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>1353431128766603264</td>\n",
              "      <td>Sun Jan 24 19:55:01 +0000 2021</td>\n",
              "      <td>‚ÄúIt‚Äôs heart stopping.‚Äù‚ÄúIt‚Äôs soul pounding.‚Äù ‚ÄúIt‚Äôs breathtaking.‚Äù üòç Take in a new perspective of Earth as seen t‚Ä¶ https://t.co/5YFkFUtTx9</td>\n",
              "      <td>821</td>\n",
              "      <td>5374</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>1352754920852697088</td>\n",
              "      <td>Fri Jan 22 23:08:00 +0000 2021</td>\n",
              "      <td>A new study shows that the seven TRAPPIST-1 planets ‚Äî the largest group of Earth-size planets ever found in a singl‚Ä¶ https://t.co/FlnGkTcnqh</td>\n",
              "      <td>841</td>\n",
              "      <td>6509</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3140</th>\n",
              "      <td>1265692470869925888</td>\n",
              "      <td>Wed May 27 17:12:55 +0000 2020</td>\n",
              "      <td>.@KellyClarkson's performance of the national anthem for #LaunchAmerica = ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê https://t.co/sRw8ocf8m2</td>\n",
              "      <td>900</td>\n",
              "      <td>5102</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3155</th>\n",
              "      <td>1265685570564603904</td>\n",
              "      <td>Wed May 27 16:45:29 +0000 2020</td>\n",
              "      <td>.@AstroBehnken = joint operations commander for the mission https://t.co/QuSYOgvRKK</td>\n",
              "      <td>1059</td>\n",
              "      <td>6036</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3156</th>\n",
              "      <td>1265685157257842690</td>\n",
              "      <td>Wed May 27 16:43:51 +0000 2020</td>\n",
              "      <td>.@Astro_Doug = Crew Dragon commander for the #LaunchAmerica mission https://t.co/xWX9Fl7kYD</td>\n",
              "      <td>1080</td>\n",
              "      <td>6030</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3171</th>\n",
              "      <td>1265643951513624579</td>\n",
              "      <td>Wed May 27 14:00:07 +0000 2020</td>\n",
              "      <td>Meet our special guest host for today's #LaunchAmerica broadcast: @Astro_Flow, who has traveled on two space shuttl‚Ä¶ https://t.co/IiGksHRUmH</td>\n",
              "      <td>1207</td>\n",
              "      <td>9941</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3194</th>\n",
              "      <td>1265386899197308928</td>\n",
              "      <td>Tue May 26 20:58:41 +0000 2020</td>\n",
              "      <td>Tomorrow, @AstroBehnken &amp;amp; @Astro_Doug become the 1st humans to launch to the @Space_Station from American soil sinc‚Ä¶ https://t.co/FLwTnLSGyA</td>\n",
              "      <td>2428</td>\n",
              "      <td>9297</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>333 rows √ó 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                status_id  ... retweet_created_at\n",
              "32    1354376310638977025  ...                NaN\n",
              "34    1354246577523740674  ...                NaN\n",
              "43    1354102852323520513  ...                NaN\n",
              "52    1353431128766603264  ...                NaN\n",
              "59    1352754920852697088  ...                NaN\n",
              "...                   ...  ...                ...\n",
              "3140  1265692470869925888  ...                NaN\n",
              "3155  1265685570564603904  ...                NaN\n",
              "3156  1265685157257842690  ...                NaN\n",
              "3171  1265643951513624579  ...                NaN\n",
              "3194  1265386899197308928  ...                NaN\n",
              "\n",
              "[333 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP-PQusizpir"
      },
      "source": [
        "15\\. Create a random sample of 100 rows from `df` without duplicates. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "sbrdPSB_zpir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "16c049ab-1933-4942-bee1-47d67c542667"
      },
      "source": [
        "# Your answer here\n",
        "df.sample(n=100, replace = False, random_state=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>retweet_created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>1333192674883592193</td>\n",
              "      <td>Sun Nov 29 23:34:37 +0000 2020</td>\n",
              "      <td>RT @Astro_Soichi: Moonstruck. Speechless. #FullMoon riseÊ∫ÄÊúà„ÅÆÂá∫„ÄÇÁ•û„ÄÖ„Åó„ÅÑ„ÄÇ https://t.co/JpP0oOk9GL</td>\n",
              "      <td>6081</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Sun Nov 29 22:36:06 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1716</th>\n",
              "      <td>1298701153899810818</td>\n",
              "      <td>Wed Aug 26 19:17:38 +0000 2020</td>\n",
              "      <td>It's awesome that women are playing such a large role here at NASA. @Astro_Stephanie, one of our‚Ä¶ https://t.co/mTHCirM6Xw</td>\n",
              "      <td>315</td>\n",
              "      <td>2219</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1334900692603965441</td>\n",
              "      <td>Fri Dec 04 16:41:41 +0000 2020</td>\n",
              "      <td>RT @NASAKennedy: We are one day away from @SpaceX's 21st Commercial Resupply Services (CRS-21) mission! üöÄ Join us today for our prelaunch e‚Ä¶</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Fri Dec 04 15:58:26 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>1331676497069842433</td>\n",
              "      <td>Wed Nov 25 19:09:52 +0000 2020</td>\n",
              "      <td>RT @NASAMars: If you have clear skies this evening where you are, look for a bright, reddish ‚Äústar‚Äù near the Moon. That‚Äôs Mars!We‚Äôre #than‚Ä¶</td>\n",
              "      <td>1272</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Wed Nov 25 18:25:30 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2567</th>\n",
              "      <td>1278343229876903939</td>\n",
              "      <td>Wed Jul 01 15:02:31 +0000 2020</td>\n",
              "      <td>With today's battery swaps now complete, @AstroBehnken is removing a device called an ‚ÄúH-fixture, located at the b‚Ä¶ https://t.co/ThvrYk7ZC9</td>\n",
              "      <td>215</td>\n",
              "      <td>2231</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1763</th>\n",
              "      <td>1296478350924488707</td>\n",
              "      <td>Thu Aug 20 16:05:00 +0000 2020</td>\n",
              "      <td>RT @NASAAstrobio: Could #OceanWorlds support life as we know it?Join @NASAGoddard scientists and astrobiologists on @Reddit today at 2pm‚Ä¶</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Thu Aug 20 15:09:02 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3133</th>\n",
              "      <td>1265696086083227648</td>\n",
              "      <td>Wed May 27 17:27:17 +0000 2020</td>\n",
              "      <td>@nishitmathur19 @SpaceX Thank you, Nishit! Onward and upward!</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2737</th>\n",
              "      <td>1273711084193619970</td>\n",
              "      <td>Thu Jun 18 20:16:01 +0000 2020</td>\n",
              "      <td>Introduced on the anniversary of Sally Ride's first flight as the first woman to lead our human spaceflight program‚Ä¶ https://t.co/l7WxNhwDqg</td>\n",
              "      <td>405</td>\n",
              "      <td>3287</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2549</th>\n",
              "      <td>1278450641409642498</td>\n",
              "      <td>Wed Jul 01 22:09:20 +0000 2020</td>\n",
              "      <td>How are we preparing our #Artemis astronauts to explore the surface of the Moon? Beyond safe spacecraft and spacesu‚Ä¶ https://t.co/wJdHiz2KjO</td>\n",
              "      <td>610</td>\n",
              "      <td>3964</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2361</th>\n",
              "      <td>1284997702393233410</td>\n",
              "      <td>Sun Jul 19 23:45:01 +0000 2020</td>\n",
              "      <td>RT @JimBridenstine: Congrats to the team that worked on @HopeMarsMission. It‚Äôs truly amazing what @UAESpaceAgency &amp;amp; @MBRSpaceCentre have ac‚Ä¶</td>\n",
              "      <td>867</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Sun Jul 19 23:41:02 +0000 2020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows √ó 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                status_id  ...              retweet_created_at\n",
              "536   1333192674883592193  ...  Sun Nov 29 22:36:06 +0000 2020\n",
              "1716  1298701153899810818  ...                             NaN\n",
              "499   1334900692603965441  ...  Fri Dec 04 15:58:26 +0000 2020\n",
              "567   1331676497069842433  ...  Wed Nov 25 18:25:30 +0000 2020\n",
              "2567  1278343229876903939  ...                             NaN\n",
              "...                   ...  ...                             ...\n",
              "1763  1296478350924488707  ...  Thu Aug 20 15:09:02 +0000 2020\n",
              "3133  1265696086083227648  ...                             NaN\n",
              "2737  1273711084193619970  ...                             NaN\n",
              "2549  1278450641409642498  ...                             NaN\n",
              "2361  1284997702393233410  ...  Sun Jul 19 23:41:02 +0000 2020\n",
              "\n",
              "[100 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fWLls1fzpis"
      },
      "source": [
        "## Dataframe Iteration & File Writing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojez1Z3ezpis"
      },
      "source": [
        "Let's continue to use `df`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeDkim_Izpis"
      },
      "source": [
        "1\\. Select the first ten values from the `text` column of `df` and print the first 30 characters of each value concatenated by the string '...'. Rows in the printed output are separated by a new line. For example, the first three rows in the printed output look as follows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzQ2LF6gzpis"
      },
      "source": [
        "It once held a lake. And what ...<br>\n",
        "I asked the team [...] to come...<br>\n",
        "Perseverance is the very first...<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ysAsVjiuzpis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b2da44-e06a-48ac-e9a0-975c1c8c484a"
      },
      "source": [
        "# Your answer here\n",
        "for text in df[:10].text:\n",
        "    print(text[:30] + \"...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It once held a lake. And what ...\n",
            "I asked the team [...] to come...\n",
            "Perseverance is the very first...\n",
            "üî¥ LIVE: Tune in for a preview ...\n",
            "RT @NASAMars: Don't forget to ...\n",
            "Just 22 more days until we #Co...\n",
            "RT @NASAExoplanets: üì£Discovery...\n",
            "RT @Space_Station: .@Astro_Ill...\n",
            "That's a wrap! @Astro_illini a...\n",
            "Success! With a bit of strengt...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PURLKY0zzpis"
      },
      "source": [
        "2\\. Select the first ten rows from `df` and print the values of each row in the following format: 'created at: CREATED_AT, text: TEXT, retweet_count: RETWEET_COUNT', where CREATED_AT, TEXT, and RETWEET_COUNT are the values from the three columns `created_at`, `text`, and `retweet_count`, respectively. Rows are separated by two new lines. For example, the first three rows in the printed output look as follows. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ssr5Auszpit"
      },
      "source": [
        "created_at: Wed Jan 27 22:12:33 +0000 2021, text: It once held a lake. And what we're going to do, as soon as we get there, is to explore the rocks that were deposi‚Ä¶ https://t.co/UW9wngvx4C, retweet_count: 72<br>\n",
        "\n",
        "created_at: Wed Jan 27 22:00:09 +0000 2021, text: I asked the team [...] to come up with something that would symbolize, to mark this challenge and thank in particu‚Ä¶ https://t.co/QH235r9zjq, retweet_count: 50<br>\n",
        "\n",
        "created_at: Wed Jan 27 21:46:25 +0000 2021, text: Perseverance is the very first rover designed to seek signs of past microbial life, by collecting and caching rock‚Ä¶ https://t.co/nn72OHRVv6, retweet_count: 135<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "JSFZ5eJIzpit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e901d5d9-9128-417d-cfd7-1e1a73dd099c"
      },
      "source": [
        "# Your answer here\n",
        "df_ten = df[:10]\n",
        "for idx, row in df_ten.iterrows():\n",
        "  print(f\"created_at: {row.created_at}, text: {row.text}, retweet_count: {row.retweet_count}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created_at: Wed Jan 27 22:12:33 +0000 2021, text: It once held a lake. And what we're going to do, as soon as we get there, is to explore the rocks that were deposi‚Ä¶ https://t.co/UW9wngvx4C, retweet_count: 72\n",
            "\n",
            "created_at: Wed Jan 27 22:00:09 +0000 2021, text: I asked the team [...] to come up with something that would symbolize, to mark this challenge and thank in particu‚Ä¶ https://t.co/QH235r9zjq, retweet_count: 50\n",
            "\n",
            "created_at: Wed Jan 27 21:46:25 +0000 2021, text: Perseverance is the very first rover designed to seek signs of past microbial life, by collecting and caching rock‚Ä¶ https://t.co/nn72OHRVv6, retweet_count: 135\n",
            "\n",
            "created_at: Wed Jan 27 21:30:27 +0000 2021, text: üî¥ LIVE: Tune in for a preview of the next Mars landing! On Feb. 18, our @NASAPersevere rover will arrive at the Red‚Ä¶ https://t.co/rHRhIrzXWR, retweet_count: 374\n",
            "\n",
            "created_at: Wed Jan 27 21:22:15 +0000 2021, text: RT @NASAMars: Don't forget to join us for today's briefing at 4:30pm ET (21:30 UTC): https://t.co/fGItMYWnFR Tag your questions #Countdown‚Ä¶, retweet_count: 137\n",
            "\n",
            "created_at: Wed Jan 27 20:04:59 +0000 2021, text: Just 22 more days until we #CountdownToMars. Our @NASAPersevere rover is nearing the end of its 292.5-million-mile‚Ä¶ https://t.co/DtT1K7l9GF, retweet_count: 406\n",
            "\n",
            "created_at: Wed Jan 27 19:32:23 +0000 2021, text: RT @NASAExoplanets: üì£Discovery alert!üì£In a first, astronomers find a system of six stars made of three eclipsing binaries. Stars orbit the‚Ä¶, retweet_count: 880\n",
            "\n",
            "created_at: Wed Jan 27 19:15:05 +0000 2021, text: RT @Space_Station: .@Astro_Illini and @AstroVicGlover completed today's spacewalk at 1:24pm ET after installing a new science antenna then‚Ä¶, retweet_count: 279\n",
            "\n",
            "created_at: Wed Jan 27 18:36:21 +0000 2021, text: That's a wrap! @Astro_illini and @AstroVicGlover concluded today's spacewalk at 1:24pm ET, following a 6-hour and 5‚Ä¶ https://t.co/JE1eRgQtFx, retweet_count: 260\n",
            "\n",
            "created_at: Wed Jan 27 18:01:20 +0000 2021, text: Success! With a bit of strength and skill, @Astro_illini removed the H-fixture from the @Space_Station, opening the‚Ä¶ https://t.co/qw0zfcfn9X, retweet_count: 211\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIq15FsWzpit"
      },
      "source": [
        "3\\. Select all rows from `df` with the `is_retweet` column value being 0 and save the resulting dataframe in a CSV file named `hw3_output.csv` in the `outcome` folder such that the column separator is a tab and it contains the index of the dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vp7PrLaszpit"
      },
      "source": [
        "# Your answer here\n",
        "df_save = df[df.is_retweet==0]\n",
        "df_save.to_csv(f\"{outcome_folder}/hw3_output.csv\", sep=\"\\t\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmtQLtZWzpiu"
      },
      "source": [
        "## Adding Columns to a Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr7iXqV-zpiu"
      },
      "source": [
        "Let's continue to use `df`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRXN6pMuzpiu"
      },
      "source": [
        "1\\. Add a new column `text_shortened` to `df` such that each value in the column is the first 30 characters of the `text` column value concatenated by the string '...'.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd0CDZrdzpiu"
      },
      "source": [
        "# Your answer here\n",
        "df[\"text_shortened\"] = df.text.apply(lambda x: x[:30] + \"...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7srUW8Sizpiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "25590a45-2f77-40d6-a346-a041b889d5bc"
      },
      "source": [
        "# Check your answer here.\n",
        "df[[\"text\", \"text_shortened\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_shortened</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It once held a lake. And what we're going to do, as soon as we get there, is to explore the rocks that were deposi‚Ä¶ https://t.co/UW9wngvx4C</td>\n",
              "      <td>It once held a lake. And what ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I asked the team [...] to come up with something that would symbolize, to mark this challenge and thank in particu‚Ä¶ https://t.co/QH235r9zjq</td>\n",
              "      <td>I asked the team [...] to come...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Perseverance is the very first rover designed to seek signs of past microbial life, by collecting and caching rock‚Ä¶ https://t.co/nn72OHRVv6</td>\n",
              "      <td>Perseverance is the very first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>üî¥ LIVE: Tune in for a preview of the next Mars landing! On Feb. 18, our @NASAPersevere rover will arrive at the Red‚Ä¶ https://t.co/rHRhIrzXWR</td>\n",
              "      <td>üî¥ LIVE: Tune in for a preview ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @NASAMars: Don't forget to join us for today's briefing at 4:30pm ET (21:30 UTC): https://t.co/fGItMYWnFR Tag your questions #Countdown‚Ä¶</td>\n",
              "      <td>RT @NASAMars: Don't forget to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3195</th>\n",
              "      <td>RT @NASAKennedy: Looking for live views of the launch pad? We got you covered. üöÄüëÄCheck out the rocket that will carry @AstroBehnken and @‚Ä¶</td>\n",
              "      <td>RT @NASAKennedy: Looking for l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3196</th>\n",
              "      <td>For the first time since 2011, we‚Äôre sending American astronauts back to space, on an American rocket, from America‚Ä¶ https://t.co/FsC1feO84c</td>\n",
              "      <td>For the first time since 2011,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3197</th>\n",
              "      <td>LIVE: Want to go behind-the-scenes of #LaunchAmerica?Join our experts on @reddit to ask questions about the missi‚Ä¶ https://t.co/p7iqJY4jyX</td>\n",
              "      <td>LIVE: Want to go behind-the-sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3198</th>\n",
              "      <td>@brandonleblanc @SpaceX @AmyShiraTeitel See you online! https://t.co/FaQ7K75sBP</td>\n",
              "      <td>@brandonleblanc @SpaceX @AmySh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3199</th>\n",
              "      <td>RT @NASAEarth: Ready to #LaunchAmerica? Tomorrow, two astronauts üë®üèª‚ÄçüöÄüë®üèª‚ÄçüöÄ are launching üöÄ to the @Space_Station from @NASAKennedy‚Äôs histori‚Ä¶</td>\n",
              "      <td>RT @NASAEarth: Ready to #Launc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3200 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                              text                     text_shortened\n",
              "0      It once held a lake. And what we're going to do, as soon as we get there, is to explore the rocks that were deposi‚Ä¶ https://t.co/UW9wngvx4C  It once held a lake. And what ...\n",
              "1      I asked the team [...] to come up with something that would symbolize, to mark this challenge and thank in particu‚Ä¶ https://t.co/QH235r9zjq  I asked the team [...] to come...\n",
              "2      Perseverance is the very first rover designed to seek signs of past microbial life, by collecting and caching rock‚Ä¶ https://t.co/nn72OHRVv6  Perseverance is the very first...\n",
              "3     üî¥ LIVE: Tune in for a preview of the next Mars landing! On Feb. 18, our @NASAPersevere rover will arrive at the Red‚Ä¶ https://t.co/rHRhIrzXWR  üî¥ LIVE: Tune in for a preview ...\n",
              "4      RT @NASAMars: Don't forget to join us for today's briefing at 4:30pm ET (21:30 UTC): https://t.co/fGItMYWnFR Tag your questions #Countdown‚Ä¶  RT @NASAMars: Don't forget to ...\n",
              "...                                                                                                                                            ...                                ...\n",
              "3195    RT @NASAKennedy: Looking for live views of the launch pad? We got you covered. üöÄüëÄCheck out the rocket that will carry @AstroBehnken and @‚Ä¶  RT @NASAKennedy: Looking for l...\n",
              "3196  For the first time since 2011, we‚Äôre sending American astronauts back to space, on an American rocket, from America‚Ä¶ https://t.co/FsC1feO84c  For the first time since 2011,...\n",
              "3197    LIVE: Want to go behind-the-scenes of #LaunchAmerica?Join our experts on @reddit to ask questions about the missi‚Ä¶ https://t.co/p7iqJY4jyX  LIVE: Want to go behind-the-sc...\n",
              "3198                                                               @brandonleblanc @SpaceX @AmyShiraTeitel See you online! https://t.co/FaQ7K75sBP  @brandonleblanc @SpaceX @AmySh...\n",
              "3199  RT @NASAEarth: Ready to #LaunchAmerica? Tomorrow, two astronauts üë®üèª‚ÄçüöÄüë®üèª‚ÄçüöÄ are launching üöÄ to the @Space_Station from @NASAKennedy‚Äôs histori‚Ä¶  RT @NASAEarth: Ready to #Launc...\n",
              "\n",
              "[3200 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYIoPqNBzpiu"
      },
      "source": [
        "2\\. Add a new column `first_last_token` to `df` such that each column value is a tuple with two elements: the first element being the first token of the `text` column value and the second one being the last token (use the <b>split</b> method). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTIKPZiYzpiv"
      },
      "source": [
        "# Your answer here\n",
        "df[\"first_last_token\"] = df.text.apply(lambda x: \"(\"+x.split(\" \")[0]+\", \"+x.split(\" \")[-1]+\")\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO2qgtUnzpiv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "2128d557-4990-4ff9-e511-ab4a50155099"
      },
      "source": [
        "# Check your answer here.\n",
        "df[[\"text\", \"first_last_token\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>first_last_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It once held a lake. And what we're going to do, as soon as we get there, is to explore the rocks that were deposi‚Ä¶ https://t.co/UW9wngvx4C</td>\n",
              "      <td>(It, https://t.co/UW9wngvx4C)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I asked the team [...] to come up with something that would symbolize, to mark this challenge and thank in particu‚Ä¶ https://t.co/QH235r9zjq</td>\n",
              "      <td>(I, https://t.co/QH235r9zjq)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Perseverance is the very first rover designed to seek signs of past microbial life, by collecting and caching rock‚Ä¶ https://t.co/nn72OHRVv6</td>\n",
              "      <td>(Perseverance, https://t.co/nn72OHRVv6)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>üî¥ LIVE: Tune in for a preview of the next Mars landing! On Feb. 18, our @NASAPersevere rover will arrive at the Red‚Ä¶ https://t.co/rHRhIrzXWR</td>\n",
              "      <td>(üî¥, https://t.co/rHRhIrzXWR)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @NASAMars: Don't forget to join us for today's briefing at 4:30pm ET (21:30 UTC): https://t.co/fGItMYWnFR Tag your questions #Countdown‚Ä¶</td>\n",
              "      <td>(RT, #Countdown‚Ä¶)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3195</th>\n",
              "      <td>RT @NASAKennedy: Looking for live views of the launch pad? We got you covered. üöÄüëÄCheck out the rocket that will carry @AstroBehnken and @‚Ä¶</td>\n",
              "      <td>(RT, @‚Ä¶)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3196</th>\n",
              "      <td>For the first time since 2011, we‚Äôre sending American astronauts back to space, on an American rocket, from America‚Ä¶ https://t.co/FsC1feO84c</td>\n",
              "      <td>(For, https://t.co/FsC1feO84c)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3197</th>\n",
              "      <td>LIVE: Want to go behind-the-scenes of #LaunchAmerica?Join our experts on @reddit to ask questions about the missi‚Ä¶ https://t.co/p7iqJY4jyX</td>\n",
              "      <td>(LIVE:, https://t.co/p7iqJY4jyX)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3198</th>\n",
              "      <td>@brandonleblanc @SpaceX @AmyShiraTeitel See you online! https://t.co/FaQ7K75sBP</td>\n",
              "      <td>(@brandonleblanc, https://t.co/FaQ7K75sBP)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3199</th>\n",
              "      <td>RT @NASAEarth: Ready to #LaunchAmerica? Tomorrow, two astronauts üë®üèª‚ÄçüöÄüë®üèª‚ÄçüöÄ are launching üöÄ to the @Space_Station from @NASAKennedy‚Äôs histori‚Ä¶</td>\n",
              "      <td>(RT, histori‚Ä¶)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3200 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                              text                            first_last_token\n",
              "0      It once held a lake. And what we're going to do, as soon as we get there, is to explore the rocks that were deposi‚Ä¶ https://t.co/UW9wngvx4C               (It, https://t.co/UW9wngvx4C)\n",
              "1      I asked the team [...] to come up with something that would symbolize, to mark this challenge and thank in particu‚Ä¶ https://t.co/QH235r9zjq                (I, https://t.co/QH235r9zjq)\n",
              "2      Perseverance is the very first rover designed to seek signs of past microbial life, by collecting and caching rock‚Ä¶ https://t.co/nn72OHRVv6     (Perseverance, https://t.co/nn72OHRVv6)\n",
              "3     üî¥ LIVE: Tune in for a preview of the next Mars landing! On Feb. 18, our @NASAPersevere rover will arrive at the Red‚Ä¶ https://t.co/rHRhIrzXWR                (üî¥, https://t.co/rHRhIrzXWR)\n",
              "4      RT @NASAMars: Don't forget to join us for today's briefing at 4:30pm ET (21:30 UTC): https://t.co/fGItMYWnFR Tag your questions #Countdown‚Ä¶                           (RT, #Countdown‚Ä¶)\n",
              "...                                                                                                                                            ...                                         ...\n",
              "3195    RT @NASAKennedy: Looking for live views of the launch pad? We got you covered. üöÄüëÄCheck out the rocket that will carry @AstroBehnken and @‚Ä¶                                    (RT, @‚Ä¶)\n",
              "3196  For the first time since 2011, we‚Äôre sending American astronauts back to space, on an American rocket, from America‚Ä¶ https://t.co/FsC1feO84c              (For, https://t.co/FsC1feO84c)\n",
              "3197    LIVE: Want to go behind-the-scenes of #LaunchAmerica?Join our experts on @reddit to ask questions about the missi‚Ä¶ https://t.co/p7iqJY4jyX            (LIVE:, https://t.co/p7iqJY4jyX)\n",
              "3198                                                               @brandonleblanc @SpaceX @AmyShiraTeitel See you online! https://t.co/FaQ7K75sBP  (@brandonleblanc, https://t.co/FaQ7K75sBP)\n",
              "3199  RT @NASAEarth: Ready to #LaunchAmerica? Tomorrow, two astronauts üë®üèª‚ÄçüöÄüë®üèª‚ÄçüöÄ are launching üöÄ to the @Space_Station from @NASAKennedy‚Äôs histori‚Ä¶                              (RT, histori‚Ä¶)\n",
              "\n",
              "[3200 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GS81gs_zpiv"
      },
      "source": [
        "3\\. Add a new column `metrics` to `df` such that each column value is a tuple with three values from the three columns `retweet_count`, `favorite_count`, and `is_retweet`, respectively, in order. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQOWiETAzpiv"
      },
      "source": [
        "# Your answer here\n",
        "# df[\"metrics\"] = df.apply(lambda x: \"(\"+ x.retweet_count +\", \"+ x.favorite_count + \", \"+ x.is_retweet +\")\", axis=1)\n",
        "                         \n",
        "def combine_columns(row):\n",
        "    rc = row.retweet_count\n",
        "    fc = row.favorite_count\n",
        "    ir = row.is_retweet\n",
        "    return f\"({rc}, {fc}, {ir})\"\n",
        "    \n",
        "df[\"metrics\"] = df.apply(lambda x: combine_columns(x), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvBRa6x-zpiw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e2099c5a-5842-4349-d343-1e63d63873a6"
      },
      "source": [
        "# Check your answer here.\n",
        "df[[\"retweet_count\", \"favorite_count\", \"is_retweet\", \"metrics\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>metrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>72</td>\n",
              "      <td>462</td>\n",
              "      <td>0</td>\n",
              "      <td>(72, 462, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>361</td>\n",
              "      <td>0</td>\n",
              "      <td>(50, 361, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>135</td>\n",
              "      <td>870</td>\n",
              "      <td>0</td>\n",
              "      <td>(135, 870, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>374</td>\n",
              "      <td>1430</td>\n",
              "      <td>0</td>\n",
              "      <td>(374, 1430, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>(137, 0, 1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3195</th>\n",
              "      <td>1197</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>(1197, 0, 1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3196</th>\n",
              "      <td>622</td>\n",
              "      <td>2614</td>\n",
              "      <td>0</td>\n",
              "      <td>(622, 2614, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3197</th>\n",
              "      <td>253</td>\n",
              "      <td>1942</td>\n",
              "      <td>0</td>\n",
              "      <td>(253, 1942, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3198</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>(2, 6, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3199</th>\n",
              "      <td>595</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>(595, 0, 1)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3200 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      retweet_count  favorite_count  is_retweet         metrics\n",
              "0                72             462           0    (72, 462, 0)\n",
              "1                50             361           0    (50, 361, 0)\n",
              "2               135             870           0   (135, 870, 0)\n",
              "3               374            1430           0  (374, 1430, 0)\n",
              "4               137               0           1     (137, 0, 1)\n",
              "...             ...             ...         ...             ...\n",
              "3195           1197               0           1    (1197, 0, 1)\n",
              "3196            622            2614           0  (622, 2614, 0)\n",
              "3197            253            1942           0  (253, 1942, 0)\n",
              "3198              2               6           0       (2, 6, 0)\n",
              "3199            595               0           1     (595, 0, 1)\n",
              "\n",
              "[3200 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri0Gl5d4zpiw"
      },
      "source": [
        "4\\. Add a new column `num_mentions` to `df` such that each column value is the number of '@' symbols in the `text` column value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pG9hffxzpix"
      },
      "source": [
        "# Your answer here\n",
        "df[\"num_mentions\"] = df.text.str.contains(\"@\") #case=falseÏù¥Î©¥, ÎåÄÏÜåÎ¨∏Ïûê Íµ¨Î∂Ñ X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnhUKGBxzpix",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "3ee5007e-422d-4204-c5e3-9f7edaab9d32"
      },
      "source": [
        "# Check your answer here.\n",
        "df[[\"text\", \"num_mentions\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>num_mentions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It once held a lake. And what we're going to do, as soon as we get there, is to explore the rocks that were deposi‚Ä¶ https://t.co/UW9wngvx4C</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I asked the team [...] to come up with something that would symbolize, to mark this challenge and thank in particu‚Ä¶ https://t.co/QH235r9zjq</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Perseverance is the very first rover designed to seek signs of past microbial life, by collecting and caching rock‚Ä¶ https://t.co/nn72OHRVv6</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>üî¥ LIVE: Tune in for a preview of the next Mars landing! On Feb. 18, our @NASAPersevere rover will arrive at the Red‚Ä¶ https://t.co/rHRhIrzXWR</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @NASAMars: Don't forget to join us for today's briefing at 4:30pm ET (21:30 UTC): https://t.co/fGItMYWnFR Tag your questions #Countdown‚Ä¶</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3195</th>\n",
              "      <td>RT @NASAKennedy: Looking for live views of the launch pad? We got you covered. üöÄüëÄCheck out the rocket that will carry @AstroBehnken and @‚Ä¶</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3196</th>\n",
              "      <td>For the first time since 2011, we‚Äôre sending American astronauts back to space, on an American rocket, from America‚Ä¶ https://t.co/FsC1feO84c</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3197</th>\n",
              "      <td>LIVE: Want to go behind-the-scenes of #LaunchAmerica?Join our experts on @reddit to ask questions about the missi‚Ä¶ https://t.co/p7iqJY4jyX</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3198</th>\n",
              "      <td>@brandonleblanc @SpaceX @AmyShiraTeitel See you online! https://t.co/FaQ7K75sBP</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3199</th>\n",
              "      <td>RT @NASAEarth: Ready to #LaunchAmerica? Tomorrow, two astronauts üë®üèª‚ÄçüöÄüë®üèª‚ÄçüöÄ are launching üöÄ to the @Space_Station from @NASAKennedy‚Äôs histori‚Ä¶</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3200 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                              text  num_mentions\n",
              "0      It once held a lake. And what we're going to do, as soon as we get there, is to explore the rocks that were deposi‚Ä¶ https://t.co/UW9wngvx4C         False\n",
              "1      I asked the team [...] to come up with something that would symbolize, to mark this challenge and thank in particu‚Ä¶ https://t.co/QH235r9zjq         False\n",
              "2      Perseverance is the very first rover designed to seek signs of past microbial life, by collecting and caching rock‚Ä¶ https://t.co/nn72OHRVv6         False\n",
              "3     üî¥ LIVE: Tune in for a preview of the next Mars landing! On Feb. 18, our @NASAPersevere rover will arrive at the Red‚Ä¶ https://t.co/rHRhIrzXWR          True\n",
              "4      RT @NASAMars: Don't forget to join us for today's briefing at 4:30pm ET (21:30 UTC): https://t.co/fGItMYWnFR Tag your questions #Countdown‚Ä¶          True\n",
              "...                                                                                                                                            ...           ...\n",
              "3195    RT @NASAKennedy: Looking for live views of the launch pad? We got you covered. üöÄüëÄCheck out the rocket that will carry @AstroBehnken and @‚Ä¶          True\n",
              "3196  For the first time since 2011, we‚Äôre sending American astronauts back to space, on an American rocket, from America‚Ä¶ https://t.co/FsC1feO84c         False\n",
              "3197    LIVE: Want to go behind-the-scenes of #LaunchAmerica?Join our experts on @reddit to ask questions about the missi‚Ä¶ https://t.co/p7iqJY4jyX          True\n",
              "3198                                                               @brandonleblanc @SpaceX @AmyShiraTeitel See you online! https://t.co/FaQ7K75sBP          True\n",
              "3199  RT @NASAEarth: Ready to #LaunchAmerica? Tomorrow, two astronauts üë®üèª‚ÄçüöÄüë®üèª‚ÄçüöÄ are launching üöÄ to the @Space_Station from @NASAKennedy‚Äôs histori‚Ä¶          True\n",
              "\n",
              "[3200 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    }
  ]
}